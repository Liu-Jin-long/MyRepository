{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==1.13.1","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:35:52.653873Z","iopub.execute_input":"2022-07-29T03:35:52.654595Z","iopub.status.idle":"2022-07-29T03:36:37.594963Z","shell.execute_reply.started":"2022-07-29T03:35:52.654499Z","shell.execute_reply":"2022-07-29T03:36:37.593833Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==1.13.1\n  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.2)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.4.0)\nRequirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.43.0)\nCollecting tensorboard<1.14.0,>=1.13.0\n  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n\u001b[?25hCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.21.6)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.37.1)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.19.4)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.16.0)\nCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.6/367.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.7.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (2.1.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.7)\nRequirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.12.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.0)\nInstalling collected packages: tensorflow-estimator, astor, keras-applications, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.4\n    Uninstalling tensorflow-2.6.4:\n      Successfully uninstalled tensorflow-2.6.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.13.1 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorflow<3.0,>=1.15.0, but you have tensorflow 1.13.1 which is incompatible.\npytorch-lightning 1.6.5 requires tensorboard>=2.2.0, but you have tensorboard 1.13.1 which is incompatible.\nexplainable-ai-sdk 1.3.3 requires tensorflow>=1.15.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport time\nimport pickle\nimport numpy as np\n\nprint(tf.__version__)\nCIFAR_DIR = '/kaggle/input/cifar10/cifar-10-batches-py'\nprint(os.listdir(CIFAR_DIR))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:37.601634Z","iopub.execute_input":"2022-07-29T03:36:37.601955Z","iopub.status.idle":"2022-07-29T03:36:38.415555Z","shell.execute_reply.started":"2022-07-29T03:36:37.601921Z","shell.execute_reply":"2022-07-29T03:36:38.414408Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"},{"name":"stdout","text":"1.13.1\n['data_batch_1', 'data_batch_2', 'batches.meta', 'test_batch', 'data_batch_3', 'data_batch_5', 'data_batch_4', 'readme.html']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_filenames = [os.path.join(CIFAR_DIR, f'data_batch_{i}') for i in range(1, 6)]\ntest_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\nprint(train_filenames)\nprint(test_filenames)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:38.417333Z","iopub.execute_input":"2022-07-29T03:36:38.417773Z","iopub.status.idle":"2022-07-29T03:36:38.425050Z","shell.execute_reply.started":"2022-07-29T03:36:38.417730Z","shell.execute_reply":"2022-07-29T03:36:38.423996Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['/kaggle/input/cifar10/cifar-10-batches-py/data_batch_1', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_2', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_3', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_4', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_5']\n['/kaggle/input/cifar10/cifar-10-batches-py/test_batch']\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(filename):\n    \"\"\"前面是图片特征，后面是图片分类标签\"\"\"\n    with open(filename, 'rb') as f:\n        data = pickle.load(f, encoding='bytes')\n        return data[b'data'], data[b'labels']\n\n\n# tensorflow.Dataset\nclass CifarData:\n    def __init__(self, filenames, need_shuffle):\n        all_data = []\n        all_lables = []\n        for filename in filenames:\n            data, labels = load_data(filename)\n            all_data.append(data)  # all_data[0]列表中10000个存有(32*32*3=)3072个数的一维列表c\n            all_lables.append(labels)  # all_data[0]列表中10000个标签值\n        self._data = np.vstack(all_data)  # 垂直方向沿轴2堆叠 变为ndarray\n        self._data = self._data / 127.5 - 1  # 归一化到范围[-1,1]\n        self._lables = np.hstack(all_lables)  # 一维列表变成ndarray\n        print(self._data.shape)  # (50000, 3072) 每一张图像展平后的结果\n        print(self._lables.shape)\n        print(self._lables[:5])\n\n        self._num_samples = self._data.shape[0]  # 样本数\n        self._need_shuffle = need_shuffle  # 进行洗牌随机\n        self._indicator = 0\n        if self._need_shuffle:\n            self._shuffle_data()\n\n    def _shuffle_data(self):\n        # 通过随机排列下标进行随机样本\n        p = np.random.permutation(self._num_samples)  # 变成随机下标\n        self._data = self._data[p]\n        self._lables = self._lables[p]\n\n    def next_batch(self, batch_size):\n        \"\"\"return batch_size samples as a batch.\"\"\"\n        end_indicator = self._indicator + batch_size\n        if end_indicator > self._num_samples:\n            if self._need_shuffle:\n                self._shuffle_data()\n                self._indicator = 0\n                end_indicator = self._indicator + batch_size\n            else:\n                raise Exception('have no more samples')\n        if end_indicator > self._num_samples:\n            # 去除不足batch_size剩余的样本\n            raise Exception('batch size is larger than the remaining samples')\n        batch_data = self._data[self._indicator:end_indicator]\n        batch_labels = self._lables[self._indicator:end_indicator]\n        self._indicator = end_indicator\n        return batch_data, batch_labels\n\n\ntrain_data = CifarData(train_filenames, True)\ntest_data = CifarData(test_filenames, False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:38.428382Z","iopub.execute_input":"2022-07-29T03:36:38.429133Z","iopub.status.idle":"2022-07-29T03:36:42.444162Z","shell.execute_reply.started":"2022-07-29T03:36:38.429093Z","shell.execute_reply":"2022-07-29T03:36:42.443048Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(50000, 3072)\n(50000,)\n[6 9 9 4 1]\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n","output_type":"stream"}]},{"cell_type":"code","source":"# 构造分组卷积块\ndef inception_block(x, output_channel_for_each_path,  # 每一个分组卷积的输出通道数\n                    name):\n    \"\"\"inception block implementation\"\"\"\n    with tf.variable_scope(name):\n        conv1_1 = tf.layers.conv2d(x,\n                                   output_channel_for_each_path[0],\n                                   (1, 1),\n                                   strides=(1, 1),\n                                   padding='same',\n                                   activation=tf.nn.relu,\n                                   name='conv1_1')\n        conv3_3 = tf.layers.conv2d(x,\n                                   output_channel_for_each_path[1],\n                                   (3, 3),\n                                   strides=(1, 1),\n                                   padding='same',\n                                   activation=tf.nn.relu,\n                                   name='conv3_3')\n        conv5_5 = tf.layers.conv2d(x,\n                                   output_channel_for_each_path[2],\n                                   (1, 1),\n                                   strides=(1, 1),\n                                   padding='same',\n                                   activation=tf.nn.relu,\n                                   name='conv5_5')\n        max_pooling = tf.layers.max_pooling2d(x,\n                                              (2, 2),\n                                              (2, 2),\n                                              name='max_pooling')\n    max_pooling_shape = max_pooling.get_shape().as_list()[1:]\n    input_shape = x.get_shape().as_list()[1:]\n    height_padding = (input_shape[0] - max_pooling_shape[0]) // 2\n    wideth_padding = (input_shape[1] - max_pooling_shape[1]) // 2\n    padding_pooling = tf.pad(max_pooling, [[0, 0], [height_padding, height_padding],\n                                           [wideth_padding, wideth_padding], [0, 0]])\n    # 在通道数维度进行合并\n    concat_layer = tf.concat([conv1_1, conv3_3, conv5_5, padding_pooling], axis=3)\n    return concat_layer","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:42.445692Z","iopub.execute_input":"2022-07-29T03:36:42.446034Z","iopub.status.idle":"2022-07-29T03:36:42.459194Z","shell.execute_reply.started":"2022-07-29T03:36:42.445998Z","shell.execute_reply":"2022-07-29T03:36:42.457877Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x = tf.placeholder(tf.float32, [None, 3072])\ny = tf.placeholder(tf.int64, [None])\nx_image = tf.reshape(x, [-1, 3, 32, 32])\nx_image = tf.transpose(x_image, perm=[0, 2, 3, 1])","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:42.460803Z","iopub.execute_input":"2022-07-29T03:36:42.461163Z","iopub.status.idle":"2022-07-29T03:36:42.514037Z","shell.execute_reply.started":"2022-07-29T03:36:42.461127Z","shell.execute_reply":"2022-07-29T03:36:42.513193Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 搭建InceptionNet\nconv1 = tf.layers.conv2d(x_image,\n                         32,\n                         (3, 3),\n                         padding='same',\n                         activation=tf.nn.relu,\n                         name='conv1')\npooling1 = tf.layers.max_pooling2d(conv1,\n                                   (2, 2),\n                                   (2, 2),\n                                   name='pool1')\ninception_2a = inception_block(pooling1,\n                               [16, 16, 16],\n                               name='inception_2a')\ninception_2b = inception_block(pooling1,\n                               [16, 16, 16],\n                               name='inception_2b')\npooling2 = tf.layers.max_pooling2d(inception_2b,\n                                   (2, 2),\n                                   (2, 2),\n                                   name='pool2')\ninception_3a = inception_block(pooling2,\n                               [16, 16, 16],\n                               name='inception_3a')\ninception_3b = inception_block(inception_3a,\n                               [16, 16, 16],\n                               name='inception_3b')\npooling3 = tf.layers.max_pooling2d(inception_3b,\n                                   (2, 2),\n                                   (2, 2),\n                                   name='pool3')\nflatten = tf.layers.flatten(pooling3)\nprint(flatten)\ny_ = tf.layers.dense(flatten, 10)\nloss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\npredict = tf.argmax(y_, 1)\ncorrect_prediction = tf.equal(predict, y)  # y是真实值\n# 计算张量维度上元素的平均值\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\nwith tf.name_scope('train_op'):\n    # 这里计算梯度并更新了梯度\n    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:42.515464Z","iopub.execute_input":"2022-07-29T03:36:42.515815Z","iopub.status.idle":"2022-07-29T03:36:43.251990Z","shell.execute_reply.started":"2022-07-29T03:36:42.515782Z","shell.execute_reply":"2022-07-29T03:36:43.250825Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Tensor(\"flatten/Reshape:0\", shape=(?, 2816), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ninit = tf.global_variables_initializer()  # 低版本tf必须要做\nbatch_size = 20\ntrain_steps = 10000\ntest_steps = 100\nwith tf.Session() as s:\n    s.run(init)  # 低版本tf必须要做\n    start = time.time()\n    for i in range(train_steps):\n        batch_data, batch_labels = train_data.next_batch(batch_size)\n        loss_val, accu_val, _ = s.run([loss, accuracy, train_op],\n                                      feed_dict={x: batch_data, y: batch_labels})\n        if (i + 1) % 100 == 0:\n            print('[Train] Step: %d, loss: %4.5f, accuracy: %4.5f'\n                  % (i + 1, loss_val, accu_val))\n            end = time.time()\n            print(f'just 100 steps take time: {end - start}s')\n            start=end\n        if (i + 1) % 1000 == 0:\n            test_data = CifarData(test_filenames, False)  # 重新拿测试集\n            all_test_accu_val = []\n            for j in range(test_steps):\n                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n                test_accu_val = s.run([accuracy],\n                                      feed_dict={x: test_batch_data, y: test_batch_labels})\n                all_test_accu_val.append(test_accu_val)\n            test_accu = np.mean(all_test_accu_val)\n            print('[Test ] Step: %d, accuracy: %4.5f' % (i + 1, test_accu))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T03:36:43.253314Z","iopub.execute_input":"2022-07-29T03:36:43.253713Z","iopub.status.idle":"2022-07-29T03:45:46.956594Z","shell.execute_reply.started":"2022-07-29T03:36:43.253657Z","shell.execute_reply":"2022-07-29T03:45:46.955570Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"CPU times: user 3 µs, sys: 0 ns, total: 3 µs\nWall time: 5.96 µs\n","output_type":"stream"},{"name":"stderr","text":"2022-07-29 03:36:43.267255: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2022-07-29 03:36:43.273146: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz\n2022-07-29 03:36:43.273615: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562f9cb34c40 executing computations on platform Host. Devices:\n2022-07-29 03:36:43.273642: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","output_type":"stream"},{"name":"stdout","text":"[Train] Step: 100, loss: 1.89746, accuracy: 0.25000\njust 100 steps take time: 5.194921493530273s\n[Train] Step: 200, loss: 1.60905, accuracy: 0.45000\njust 100 steps take time: 5.525650262832642s\n[Train] Step: 300, loss: 1.61515, accuracy: 0.30000\njust 100 steps take time: 6.0603015422821045s\n[Train] Step: 400, loss: 1.80378, accuracy: 0.25000\njust 100 steps take time: 6.656144857406616s\n[Train] Step: 500, loss: 1.72245, accuracy: 0.50000\njust 100 steps take time: 5.250305414199829s\n[Train] Step: 600, loss: 1.70323, accuracy: 0.35000\njust 100 steps take time: 5.181459426879883s\n[Train] Step: 700, loss: 1.63959, accuracy: 0.25000\njust 100 steps take time: 4.916364908218384s\n[Train] Step: 800, loss: 1.57610, accuracy: 0.40000\njust 100 steps take time: 5.239777565002441s\n[Train] Step: 900, loss: 1.30174, accuracy: 0.60000\njust 100 steps take time: 5.028223037719727s\n[Train] Step: 1000, loss: 1.22131, accuracy: 0.55000\njust 100 steps take time: 5.813836574554443s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 1000, accuracy: 0.54400\n[Train] Step: 1100, loss: 1.16870, accuracy: 0.55000\njust 100 steps take time: 6.386850357055664s\n[Train] Step: 1200, loss: 1.05556, accuracy: 0.70000\njust 100 steps take time: 5.27167010307312s\n[Train] Step: 1300, loss: 1.29866, accuracy: 0.45000\njust 100 steps take time: 5.032731294631958s\n[Train] Step: 1400, loss: 1.12768, accuracy: 0.65000\njust 100 steps take time: 6.669999837875366s\n[Train] Step: 1500, loss: 1.31479, accuracy: 0.50000\njust 100 steps take time: 5.9127607345581055s\n[Train] Step: 1600, loss: 0.84636, accuracy: 0.65000\njust 100 steps take time: 5.1733880043029785s\n[Train] Step: 1700, loss: 1.26609, accuracy: 0.55000\njust 100 steps take time: 5.343029260635376s\n[Train] Step: 1800, loss: 1.61753, accuracy: 0.50000\njust 100 steps take time: 5.416579723358154s\n[Train] Step: 1900, loss: 1.25284, accuracy: 0.60000\njust 100 steps take time: 5.075918436050415s\n[Train] Step: 2000, loss: 1.22858, accuracy: 0.50000\njust 100 steps take time: 5.260362863540649s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 2000, accuracy: 0.59750\n[Train] Step: 2100, loss: 1.06838, accuracy: 0.60000\njust 100 steps take time: 6.895913600921631s\n[Train] Step: 2200, loss: 1.07781, accuracy: 0.60000\njust 100 steps take time: 4.469129800796509s\n[Train] Step: 2300, loss: 0.68638, accuracy: 0.80000\njust 100 steps take time: 4.472514867782593s\n[Train] Step: 2400, loss: 1.22411, accuracy: 0.55000\njust 100 steps take time: 4.784963607788086s\n[Train] Step: 2500, loss: 1.02620, accuracy: 0.65000\njust 100 steps take time: 4.486595392227173s\n[Train] Step: 2600, loss: 0.90479, accuracy: 0.65000\njust 100 steps take time: 5.192784786224365s\n[Train] Step: 2700, loss: 1.12337, accuracy: 0.70000\njust 100 steps take time: 5.043609380722046s\n[Train] Step: 2800, loss: 1.24520, accuracy: 0.60000\njust 100 steps take time: 6.10155177116394s\n[Train] Step: 2900, loss: 0.86075, accuracy: 0.65000\njust 100 steps take time: 5.044309139251709s\n[Train] Step: 3000, loss: 0.79577, accuracy: 0.70000\njust 100 steps take time: 5.388212203979492s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 3000, accuracy: 0.64900\n[Train] Step: 3100, loss: 0.90834, accuracy: 0.70000\njust 100 steps take time: 6.55348014831543s\n[Train] Step: 3200, loss: 0.94681, accuracy: 0.65000\njust 100 steps take time: 4.854082107543945s\n[Train] Step: 3300, loss: 1.21333, accuracy: 0.45000\njust 100 steps take time: 4.498337507247925s\n[Train] Step: 3400, loss: 0.54328, accuracy: 0.90000\njust 100 steps take time: 5.286172866821289s\n[Train] Step: 3500, loss: 1.11493, accuracy: 0.65000\njust 100 steps take time: 4.401733160018921s\n[Train] Step: 3600, loss: 1.14067, accuracy: 0.60000\njust 100 steps take time: 4.482276916503906s\n[Train] Step: 3700, loss: 1.23806, accuracy: 0.70000\njust 100 steps take time: 4.756961107254028s\n[Train] Step: 3800, loss: 0.42922, accuracy: 0.85000\njust 100 steps take time: 4.462666749954224s\n[Train] Step: 3900, loss: 1.20431, accuracy: 0.55000\njust 100 steps take time: 4.802631378173828s\n[Train] Step: 4000, loss: 1.24530, accuracy: 0.60000\njust 100 steps take time: 4.662131071090698s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 4000, accuracy: 0.65200\n[Train] Step: 4100, loss: 0.94286, accuracy: 0.80000\njust 100 steps take time: 7.4413743019104s\n[Train] Step: 4200, loss: 1.08982, accuracy: 0.60000\njust 100 steps take time: 5.1016459465026855s\n[Train] Step: 4300, loss: 0.77139, accuracy: 0.80000\njust 100 steps take time: 5.30184531211853s\n[Train] Step: 4400, loss: 0.86161, accuracy: 0.70000\njust 100 steps take time: 5.117394924163818s\n[Train] Step: 4500, loss: 0.97657, accuracy: 0.60000\njust 100 steps take time: 5.4800286293029785s\n[Train] Step: 4600, loss: 0.63291, accuracy: 0.75000\njust 100 steps take time: 5.711609601974487s\n[Train] Step: 4700, loss: 0.64910, accuracy: 0.75000\njust 100 steps take time: 5.322036027908325s\n[Train] Step: 4800, loss: 1.25845, accuracy: 0.70000\njust 100 steps take time: 5.076087951660156s\n[Train] Step: 4900, loss: 1.31614, accuracy: 0.65000\njust 100 steps take time: 5.3436150550842285s\n[Train] Step: 5000, loss: 0.72782, accuracy: 0.80000\njust 100 steps take time: 5.087759971618652s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 5000, accuracy: 0.67950\n[Train] Step: 5100, loss: 0.89088, accuracy: 0.75000\njust 100 steps take time: 7.335493564605713s\n[Train] Step: 5200, loss: 0.60560, accuracy: 0.80000\njust 100 steps take time: 5.767462491989136s\n[Train] Step: 5300, loss: 0.90679, accuracy: 0.70000\njust 100 steps take time: 5.295419692993164s\n[Train] Step: 5400, loss: 0.56476, accuracy: 0.80000\njust 100 steps take time: 5.072810888290405s\n[Train] Step: 5500, loss: 0.83856, accuracy: 0.70000\njust 100 steps take time: 5.397751569747925s\n[Train] Step: 5600, loss: 0.90507, accuracy: 0.75000\njust 100 steps take time: 5.0818095207214355s\n[Train] Step: 5700, loss: 0.74634, accuracy: 0.85000\njust 100 steps take time: 5.322255611419678s\n[Train] Step: 5800, loss: 0.53407, accuracy: 0.85000\njust 100 steps take time: 5.698446750640869s\n[Train] Step: 5900, loss: 1.24204, accuracy: 0.45000\njust 100 steps take time: 5.457808017730713s\n[Train] Step: 6000, loss: 0.75908, accuracy: 0.75000\njust 100 steps take time: 5.241647958755493s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 6000, accuracy: 0.67300\n[Train] Step: 6100, loss: 0.92665, accuracy: 0.65000\njust 100 steps take time: 6.424736499786377s\n[Train] Step: 6200, loss: 1.27944, accuracy: 0.70000\njust 100 steps take time: 4.999877452850342s\n[Train] Step: 6300, loss: 0.74169, accuracy: 0.75000\njust 100 steps take time: 5.477718353271484s\n[Train] Step: 6400, loss: 1.15186, accuracy: 0.60000\njust 100 steps take time: 5.6516432762146s\n[Train] Step: 6500, loss: 1.73946, accuracy: 0.45000\njust 100 steps take time: 5.325942039489746s\n[Train] Step: 6600, loss: 0.69305, accuracy: 0.75000\njust 100 steps take time: 4.972599983215332s\n[Train] Step: 6700, loss: 0.46656, accuracy: 0.85000\njust 100 steps take time: 5.334822416305542s\n[Train] Step: 6800, loss: 0.51728, accuracy: 0.80000\njust 100 steps take time: 5.020416259765625s\n[Train] Step: 6900, loss: 0.72450, accuracy: 0.80000\njust 100 steps take time: 5.35513162612915s\n[Train] Step: 7000, loss: 0.75026, accuracy: 0.75000\njust 100 steps take time: 5.68209171295166s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 7000, accuracy: 0.70500\n[Train] Step: 7100, loss: 0.91678, accuracy: 0.65000\njust 100 steps take time: 6.902829885482788s\n[Train] Step: 7200, loss: 0.63023, accuracy: 0.80000\njust 100 steps take time: 5.104783058166504s\n[Train] Step: 7300, loss: 0.54562, accuracy: 0.75000\njust 100 steps take time: 5.31075382232666s\n[Train] Step: 7400, loss: 0.71027, accuracy: 0.65000\njust 100 steps take time: 5.078935861587524s\n[Train] Step: 7500, loss: 0.75452, accuracy: 0.75000\njust 100 steps take time: 5.482303142547607s\n[Train] Step: 7600, loss: 0.56796, accuracy: 0.80000\njust 100 steps take time: 6.037032127380371s\n[Train] Step: 7700, loss: 0.98546, accuracy: 0.50000\njust 100 steps take time: 5.40955114364624s\n[Train] Step: 7800, loss: 0.53383, accuracy: 0.85000\njust 100 steps take time: 5.046985149383545s\n[Train] Step: 7900, loss: 0.35255, accuracy: 0.90000\njust 100 steps take time: 5.183309078216553s\n[Train] Step: 8000, loss: 0.40880, accuracy: 0.90000\njust 100 steps take time: 5.00201416015625s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 8000, accuracy: 0.70650\n[Train] Step: 8100, loss: 0.78188, accuracy: 0.70000\njust 100 steps take time: 7.576174020767212s\n[Train] Step: 8200, loss: 0.85652, accuracy: 0.70000\njust 100 steps take time: 5.084103345870972s\n[Train] Step: 8300, loss: 0.75575, accuracy: 0.70000\njust 100 steps take time: 5.371893882751465s\n[Train] Step: 8400, loss: 0.82125, accuracy: 0.75000\njust 100 steps take time: 5.203855276107788s\n[Train] Step: 8500, loss: 1.05232, accuracy: 0.65000\njust 100 steps take time: 5.535924434661865s\n[Train] Step: 8600, loss: 0.56756, accuracy: 0.85000\njust 100 steps take time: 5.058014154434204s\n[Train] Step: 8700, loss: 1.22261, accuracy: 0.55000\njust 100 steps take time: 5.975902795791626s\n[Train] Step: 8800, loss: 0.84155, accuracy: 0.75000\njust 100 steps take time: 5.175545692443848s\n[Train] Step: 8900, loss: 0.70245, accuracy: 0.80000\njust 100 steps take time: 5.5079169273376465s\n[Train] Step: 9000, loss: 0.69470, accuracy: 0.75000\njust 100 steps take time: 5.087763071060181s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 9000, accuracy: 0.71200\n[Train] Step: 9100, loss: 0.58944, accuracy: 0.80000\njust 100 steps take time: 7.034553289413452s\n[Train] Step: 9200, loss: 0.32855, accuracy: 0.95000\njust 100 steps take time: 5.277834177017212s\n[Train] Step: 9300, loss: 0.48213, accuracy: 0.85000\njust 100 steps take time: 6.186235189437866s\n[Train] Step: 9400, loss: 0.94129, accuracy: 0.70000\njust 100 steps take time: 5.115645408630371s\n[Train] Step: 9500, loss: 0.83849, accuracy: 0.80000\njust 100 steps take time: 5.531026363372803s\n[Train] Step: 9600, loss: 1.04606, accuracy: 0.65000\njust 100 steps take time: 5.2532713413238525s\n[Train] Step: 9700, loss: 0.53078, accuracy: 0.75000\njust 100 steps take time: 5.414137840270996s\n[Train] Step: 9800, loss: 0.65772, accuracy: 0.75000\njust 100 steps take time: 5.073591232299805s\n[Train] Step: 9900, loss: 0.62307, accuracy: 0.80000\njust 100 steps take time: 5.96207857131958s\n[Train] Step: 10000, loss: 0.76347, accuracy: 0.65000\njust 100 steps take time: 5.122639894485474s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n[Test ] Step: 10000, accuracy: 0.72050\n","output_type":"stream"}]}]}