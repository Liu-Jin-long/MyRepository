{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a9e9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:12.836734Z",
     "iopub.status.busy": "2022-08-03T09:36:12.836057Z",
     "iopub.status.idle": "2022-08-03T09:36:19.822582Z",
     "shell.execute_reply": "2022-08-03T09:36:19.821148Z"
    },
    "papermill": {
     "duration": 7.000568,
     "end_time": "2022-08-03T09:36:19.826017",
     "exception": false,
     "start_time": "2022-08-03T09:36:12.825449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.4\n",
      "sys.version_info(major=3, minor=7, micro=12, releaselevel='final', serial=0)\n",
      "matplotlib 3.5.2\n",
      "numpy 1.21.6\n",
      "pandas 1.3.5\n",
      "sklearn 1.0.2\n",
      "tensorflow 2.6.4\n",
      "keras.api._v2.keras 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec990d2",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:19.843911Z",
     "iopub.status.busy": "2022-08-03T09:36:19.842395Z",
     "iopub.status.idle": "2022-08-03T09:36:19.870278Z",
     "shell.execute_reply": "2022-08-03T09:36:19.869065Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038919,
     "end_time": "2022-08-03T09:36:19.872815",
     "exception": false,
     "start_time": "2022-08-03T09:36:19.833896",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "input_filepath = '../input/shakespeare/shakespeare.txt'\n",
    "text = open(input_filepath, 'r').read()\n",
    "print(len(text))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21e7d70",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:19.890092Z",
     "iopub.status.busy": "2022-08-03T09:36:19.889175Z",
     "iopub.status.idle": "2022-08-03T09:36:19.912649Z",
     "shell.execute_reply": "2022-08-03T09:36:19.911449Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035802,
     "end_time": "2022-08-03T09:36:19.916296",
     "exception": false,
     "start_time": "2022-08-03T09:36:19.880494",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a2c247",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:19.935491Z",
     "iopub.status.busy": "2022-08-03T09:36:19.934283Z",
     "iopub.status.idle": "2022-08-03T09:36:19.941881Z",
     "shell.execute_reply": "2022-08-03T09:36:19.940096Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019305,
     "end_time": "2022-08-03T09:36:19.944348",
     "exception": false,
     "start_time": "2022-08-03T09:36:19.925043",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "char2index = {char: index for index, char in enumerate(vocab)}\n",
    "print(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d15649",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:19.961417Z",
     "iopub.status.busy": "2022-08-03T09:36:19.960635Z",
     "iopub.status.idle": "2022-08-03T09:36:19.968522Z",
     "shell.execute_reply": "2022-08-03T09:36:19.966675Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018956,
     "end_time": "2022-08-03T09:36:19.970905",
     "exception": false,
     "start_time": "2022-08-03T09:36:19.951949",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "index2char = np.array(vocab)\n",
    "print(index2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc633555",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:19.989628Z",
     "iopub.status.busy": "2022-08-03T09:36:19.988505Z",
     "iopub.status.idle": "2022-08-03T09:36:20.198946Z",
     "shell.execute_reply": "2022-08-03T09:36:20.196334Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.224305,
     "end_time": "2022-08-03T09:36:20.204332",
     "exception": false,
     "start_time": "2022-08-03T09:36:19.980027",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,)\n",
      "1115394\n",
      "[18 47 56 57 58  1 15 47 58 47]\n",
      "First Citi\n"
     ]
    }
   ],
   "source": [
    "text_as_int = np.array([char2index[c] for c in text])\n",
    "print(text_as_int.shape)\n",
    "print(len(text_as_int))\n",
    "print(text_as_int[:10])\n",
    "print(text[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e71ac5d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:20.252690Z",
     "iopub.status.busy": "2022-08-03T09:36:20.252118Z",
     "iopub.status.idle": "2022-08-03T09:36:20.263707Z",
     "shell.execute_reply": "2022-08-03T09:36:20.262245Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.039618,
     "end_time": "2022-08-03T09:36:20.268355",
     "exception": false,
     "start_time": "2022-08-03T09:36:20.228737",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_input_target(id_text):\n",
    "    \"\"\"abcde -> abcd,bcde  输入是abcd，输出是bcde\"\"\"\n",
    "    return id_text[0:-1], id_text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13c1a78",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:20.291117Z",
     "iopub.status.busy": "2022-08-03T09:36:20.290710Z",
     "iopub.status.idle": "2022-08-03T09:36:23.442031Z",
     "shell.execute_reply": "2022-08-03T09:36:23.441008Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.163232,
     "end_time": "2022-08-03T09:36:23.445281",
     "exception": false,
     "start_time": "2022-08-03T09:36:20.282049",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int64) F\n",
      "tf.Tensor(47, shape=(), dtype=int64) i\n",
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int64)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int64)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 09:36:20.387711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:20.541245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:20.542193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:20.549293: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-03 09:36:20.549816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:20.550860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:20.551772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:22.981181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:22.982076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:22.982815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 09:36:22.983419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequence_length = 100\n",
    "# 输入sequence_length+1各字符 返回sequence_length个字符\n",
    "# batch将字符转换为句子序列  drop_remainder丢掉最后不足一批的余数\n",
    "sequence_dataset = char_dataset.batch(sequence_length + 1, drop_remainder=True)\n",
    "\n",
    "for char_id in char_dataset.take(2):\n",
    "    print(char_id, index2char[char_id.numpy()])\n",
    "for sequence_id in sequence_dataset.take(2):\n",
    "    print(sequence_id)\n",
    "    print(repr(''.join(index2char[sequence_id.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b913345",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:23.462402Z",
     "iopub.status.busy": "2022-08-03T09:36:23.461503Z",
     "iopub.status.idle": "2022-08-03T09:36:23.584690Z",
     "shell.execute_reply": "2022-08-03T09:36:23.583330Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.13354,
     "end_time": "2022-08-03T09:36:23.587091",
     "exception": false,
     "start_time": "2022-08-03T09:36:23.453551",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 09:36:23.537076: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1 58\n",
      " 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0 13\n",
      " 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8  0\n",
      "  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1 63\n",
      " 53 59  1 49], shape=(100,), dtype=int64)\n",
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# 做映射得到输入和输出\n",
    "sequence_dataset = sequence_dataset.map(split_input_target)\n",
    "for item_input, item_output in sequence_dataset.take(2):\n",
    "    print(item_input)\n",
    "    print(item_output)\n",
    "print(sequence_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "486fd905",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:23.605840Z",
     "iopub.status.busy": "2022-08-03T09:36:23.604948Z",
     "iopub.status.idle": "2022-08-03T09:36:23.616207Z",
     "shell.execute_reply": "2022-08-03T09:36:23.614906Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023733,
     "end_time": "2022-08-03T09:36:23.618948",
     "exception": false,
     "start_time": "2022-08-03T09:36:23.595215",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "# 选buffer_size个数据进行shuffle可以避免内存不足，从缓冲区中随机读出一个后，从原数据集的顺序元素补入缓冲区\n",
    "sequence_dataset = sequence_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "print(sequence_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c0b3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:23.636017Z",
     "iopub.status.busy": "2022-08-03T09:36:23.635411Z",
     "iopub.status.idle": "2022-08-03T09:36:23.643433Z",
     "shell.execute_reply": "2022-08-03T09:36:23.642269Z"
    },
    "papermill": {
     "duration": 0.019086,
     "end_time": "2022-08-03T09:36:23.646280",
     "exception": false,
     "start_time": "2022-08-03T09:36:23.627194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "print(len(sequence_dataset))\n",
    "print(len(text_as_int)//(sequence_length + 1)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45874b9c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:23.668666Z",
     "iopub.status.busy": "2022-08-03T09:36:23.668340Z",
     "iopub.status.idle": "2022-08-03T09:36:23.800624Z",
     "shell.execute_reply": "2022-08-03T09:36:23.799398Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.144195,
     "end_time": "2022-08-03T09:36:23.803168",
     "exception": false,
     "start_time": "2022-08-03T09:36:23.658973",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256 # 资料较小 增大维度\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                               batch_input_shape=[batch_size, None]),# None表示不定长序列\n",
    "        keras.layers.SimpleRNN(units=rnn_units,\n",
    "                               stateful=True,  # 是否把上一批最后返回的状态添加到下一批作为输入\n",
    "                               recurrent_initializer='glorot_uniform',\n",
    "                               return_sequences=True),  # 返回所有输出\n",
    "        keras.layers.Dense(vocab_size),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units, batch_size=batch_size)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64aabe21",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:23.822207Z",
     "iopub.status.busy": "2022-08-03T09:36:23.821834Z",
     "iopub.status.idle": "2022-08-03T09:36:23.836481Z",
     "shell.execute_reply": "2022-08-03T09:36:23.835026Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028541,
     "end_time": "2022-08-03T09:36:23.840822",
     "exception": false,
     "start_time": "2022-08-03T09:36:23.812281",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'embedding/embeddings:0' shape=(65, 256) dtype=float32, numpy=\n",
      "array([[ 0.0315897 ,  0.0191695 , -0.02248891, ...,  0.00252968,\n",
      "        -0.0051024 ,  0.03776758],\n",
      "       [-0.03473364,  0.00246806, -0.04956435, ..., -0.0260577 ,\n",
      "        -0.04053782, -0.04774687],\n",
      "       [ 0.02023702,  0.02073567, -0.01848514, ...,  0.01088298,\n",
      "         0.02291042,  0.03920123],\n",
      "       ...,\n",
      "       [ 0.00585954, -0.04024822, -0.02104069, ...,  0.02204395,\n",
      "        -0.035839  ,  0.02105465],\n",
      "       [ 0.03400784, -0.00209029,  0.01029694, ..., -0.00064523,\n",
      "         0.03632439,  0.00841641],\n",
      "       [-0.0074083 ,  0.02868542, -0.00435374, ...,  0.03057984,\n",
      "         0.01815863,  0.03489191]], dtype=float32)>, <tf.Variable 'simple_rnn/simple_rnn_cell/kernel:0' shape=(256, 1024) dtype=float32, numpy=\n",
      "array([[-0.03398598,  0.02765952,  0.05117539, ..., -0.05452574,\n",
      "         0.04890401, -0.02409996],\n",
      "       [-0.06255478, -0.00223817, -0.05884085, ..., -0.01992139,\n",
      "        -0.06477816,  0.00636961],\n",
      "       [ 0.00321271, -0.03928835, -0.00174833, ..., -0.035777  ,\n",
      "         0.03718217, -0.01049071],\n",
      "       ...,\n",
      "       [-0.04195042, -0.03201485,  0.06299558, ..., -0.01963253,\n",
      "         0.02385168,  0.03389107],\n",
      "       [ 0.00132949, -0.01501456,  0.02635343, ..., -0.04945995,\n",
      "        -0.05580964, -0.03423727],\n",
      "       [ 0.02990773,  0.03263675, -0.04336972, ...,  0.04250856,\n",
      "         0.00995625, -0.03281231]], dtype=float32)>, <tf.Variable 'simple_rnn/simple_rnn_cell/recurrent_kernel:0' shape=(1024, 1024) dtype=float32, numpy=\n",
      "array([[-0.0429388 ,  0.00294944, -0.00701518, ...,  0.03151521,\n",
      "         0.02171554, -0.02653097],\n",
      "       [ 0.02095134,  0.0123356 ,  0.03651163, ..., -0.05136366,\n",
      "        -0.00804269,  0.03165185],\n",
      "       [ 0.0061718 ,  0.04750242,  0.01464409, ..., -0.00966261,\n",
      "         0.05002334,  0.00709344],\n",
      "       ...,\n",
      "       [ 0.03431228, -0.00751433,  0.03046167, ...,  0.01374251,\n",
      "        -0.04416999, -0.00317207],\n",
      "       [ 0.03838395, -0.04859398, -0.01963598, ...,  0.01738765,\n",
      "        -0.01348044,  0.00893438],\n",
      "       [-0.00708949,  0.00648944,  0.03809318, ...,  0.0342778 ,\n",
      "         0.00741748,  0.02561202]], dtype=float32)>, <tf.Variable 'simple_rnn/simple_rnn_cell/bias:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(1024, 65) dtype=float32, numpy=\n",
      "array([[-0.07399444, -0.00718717,  0.06355417, ..., -0.04180061,\n",
      "        -0.01018482,  0.01092184],\n",
      "       [-0.0276051 ,  0.03461377, -0.03451579, ..., -0.03581717,\n",
      "        -0.06232993,  0.00212838],\n",
      "       [ 0.04692326, -0.02015502,  0.04191123, ...,  0.04939721,\n",
      "        -0.02480611,  0.00070509],\n",
      "       ...,\n",
      "       [-0.07107957, -0.06461626, -0.06502867, ...,  0.0234256 ,\n",
      "        -0.00090259, -0.02483395],\n",
      "       [-0.01555082, -0.03369601,  0.04311023, ..., -0.01872293,\n",
      "         0.038096  , -0.02358974],\n",
      "       [ 0.06577131, -0.00361975, -0.05627633, ...,  0.01783224,\n",
      "        -0.0408218 ,  0.0396216 ]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(65,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec26fa4b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:23.858065Z",
     "iopub.status.busy": "2022-08-03T09:36:23.857763Z",
     "iopub.status.idle": "2022-08-03T09:36:27.512463Z",
     "shell.execute_reply": "2022-08-03T09:36:27.508672Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.666039,
     "end_time": "2022-08-03T09:36:27.515307",
     "exception": false,
     "start_time": "2022-08-03T09:36:23.849268",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.0277677  -0.00307428 -0.01136489 ... -0.02350267  0.01461161\n",
      "    0.0019732 ]\n",
      "  [ 0.01010692  0.04443358  0.05428067 ...  0.02439065  0.02949676\n",
      "    0.02530561]\n",
      "  [-0.03607504 -0.01973029  0.07881797 ...  0.01662827 -0.01038327\n",
      "    0.00734811]\n",
      "  ...\n",
      "  [ 0.11734699  0.39395094  0.0251657  ...  0.10838296  0.1353434\n",
      "    0.00128112]\n",
      "  [-0.08809775  0.06264967 -0.03204473 ...  0.03523269 -0.01832261\n",
      "   -0.01624823]\n",
      "  [-0.18793745 -0.2094123  -0.11055788 ...  0.06602431  0.15891182\n",
      "    0.07269562]]\n",
      "\n",
      " [[ 0.01691867  0.02228602  0.02628811 ... -0.02378176 -0.01417266\n",
      "    0.03836555]\n",
      "  [ 0.02831957 -0.00686338  0.02477144 ... -0.05904023  0.01052604\n",
      "    0.01227409]\n",
      "  [-0.03546701 -0.02310277 -0.02865003 ...  0.00533582  0.01301381\n",
      "   -0.00470249]\n",
      "  ...\n",
      "  [-0.03440933  0.36867595 -0.29875845 ... -0.09362227  0.02077944\n",
      "   -0.01168906]\n",
      "  [-0.10252287  0.08922808  0.11379665 ...  0.20371579  0.1979198\n",
      "   -0.23882915]\n",
      "  [ 0.26593766  0.16142857  0.02293691 ... -0.06974638 -0.01207031\n",
      "    0.10960422]]\n",
      "\n",
      " [[-0.00164865 -0.0285813  -0.02646327 ... -0.01535641  0.01623636\n",
      "    0.02020578]\n",
      "  [-0.05804484  0.01774923 -0.06922583 ... -0.01359325  0.00127977\n",
      "   -0.03226785]\n",
      "  [-0.01358336  0.0017331  -0.03490172 ... -0.02982757  0.00988072\n",
      "    0.00396851]\n",
      "  ...\n",
      "  [-0.04597048 -0.21620378  0.20782983 ...  0.04341026  0.04376652\n",
      "    0.07446548]\n",
      "  [ 0.08264275  0.23935868  0.04229574 ... -0.04114     0.06136825\n",
      "   -0.00402736]\n",
      "  [-0.01298986  0.17779705  0.00682131 ... -0.1317733  -0.07380378\n",
      "   -0.0545954 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00607617 -0.01520154  0.00344496 ... -0.0111472  -0.01449546\n",
      "   -0.01639256]\n",
      "  [-0.01763027  0.01728466  0.04657069 ...  0.04748539 -0.00798978\n",
      "    0.0113854 ]\n",
      "  [ 0.03131127 -0.05654407  0.14000686 ...  0.03381317 -0.03670895\n",
      "   -0.04397405]\n",
      "  ...\n",
      "  [-0.10495298  0.18732402 -0.08316711 ... -0.04831386  0.10276739\n",
      "   -0.1318453 ]\n",
      "  [-0.1298651   0.1496526   0.08826919 ... -0.11074872 -0.06404836\n",
      "   -0.32122326]\n",
      "  [-0.22640762 -0.04170559  0.08604986 ...  0.16144702  0.05641747\n",
      "   -0.0020463 ]]\n",
      "\n",
      " [[-0.00164865 -0.0285813  -0.02646327 ... -0.01535641  0.01623636\n",
      "    0.02020578]\n",
      "  [-0.05700556  0.01441516 -0.08387619 ... -0.03623497  0.00137716\n",
      "    0.00894282]\n",
      "  [-0.06036298  0.02735288 -0.05103576 ... -0.0668411   0.05246971\n",
      "   -0.00500592]\n",
      "  ...\n",
      "  [ 0.14622232  0.20891482  0.17662814 ... -0.18963519 -0.03083816\n",
      "   -0.12474482]\n",
      "  [-0.14211655 -0.03218766  0.14203644 ...  0.04720243  0.03234969\n",
      "    0.12051403]\n",
      "  [-0.16727722 -0.16135742 -0.03027818 ...  0.18045978 -0.06565423\n",
      "   -0.05527543]]\n",
      "\n",
      " [[-0.0194159   0.02179177  0.02620492 ...  0.04785544 -0.00158986\n",
      "    0.02088417]\n",
      "  [-0.01416769  0.00900302  0.04343131 ... -0.02767926 -0.03257846\n",
      "   -0.00157269]\n",
      "  [ 0.02485313 -0.08807112  0.01817746 ...  0.03805569  0.01633102\n",
      "    0.04394521]\n",
      "  ...\n",
      "  [-0.14943299  0.05185948 -0.21182048 ... -0.11236678  0.00403313\n",
      "   -0.0231272 ]\n",
      "  [-0.11375556  0.10233736  0.11604691 ...  0.09956524  0.00108007\n",
      "   -0.04319501]\n",
      "  [-0.02099758  0.08319968  0.13312665 ...  0.0557042  -0.05776133\n",
      "    0.09559033]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in sequence_dataset.take(1):\n",
    "    # 把model当函数来用，实际是调用类的call方法\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07506ed",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.535906Z",
     "iopub.status.busy": "2022-08-03T09:36:27.534069Z",
     "iopub.status.idle": "2022-08-03T09:36:27.550759Z",
     "shell.execute_reply": "2022-08-03T09:36:27.548542Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02939,
     "end_time": "2022-08-03T09:36:27.553695",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.524305",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.0277677  -0.00307428 -0.01136489 -0.02592429 -0.03541304  0.05327918\n",
      "  0.03731832  0.03630592 -0.02428248 -0.02034934 -0.00110926 -0.02361733\n",
      " -0.00488487  0.0073754  -0.00180079  0.03579012  0.02962378  0.02126725\n",
      "  0.02433565 -0.02989892 -0.00509168  0.04281706  0.03638208  0.00128084\n",
      "  0.00827455  0.00774063 -0.02448355  0.02234148  0.05311988  0.04340787\n",
      " -0.02852925 -0.0302019  -0.04263079  0.03580119 -0.00705556  0.02946792\n",
      " -0.00340241  0.00376599  0.03039584 -0.00544588  0.00809595  0.01556165\n",
      " -0.05214859 -0.05935791 -0.01086076 -0.01550933 -0.00858685 -0.04007464\n",
      " -0.04232285 -0.02414624  0.0251887  -0.02858887 -0.0092003   0.01913104\n",
      "  0.02768249  0.00738442 -0.00983901  0.01824012 -0.04077822 -0.04698012\n",
      "  0.05142738  0.00080016 -0.02350267  0.01461161  0.0019732 ], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(example_batch_predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373d84a2",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.575587Z",
     "iopub.status.busy": "2022-08-03T09:36:27.573473Z",
     "iopub.status.idle": "2022-08-03T09:36:27.582998Z",
     "shell.execute_reply": "2022-08-03T09:36:27.581550Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023515,
     "end_time": "2022-08-03T09:36:27.586779",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.563264",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.0277677  -0.00307428 -0.01136489 ... -0.02350267  0.01461161\n",
      "   0.0019732 ]\n",
      " [ 0.01010692  0.04443358  0.05428067 ...  0.02439065  0.02949676\n",
      "   0.02530561]\n",
      " [-0.03607504 -0.01973029  0.07881797 ...  0.01662827 -0.01038327\n",
      "   0.00734811]\n",
      " ...\n",
      " [ 0.11734699  0.39395094  0.0251657  ...  0.10838296  0.1353434\n",
      "   0.00128112]\n",
      " [-0.08809775  0.06264967 -0.03204473 ...  0.03523269 -0.01832261\n",
      "  -0.01624823]\n",
      " [-0.18793745 -0.2094123  -0.11055788 ...  0.06602431  0.15891182\n",
      "   0.07269562]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(example_batch_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fc96453",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.607982Z",
     "iopub.status.busy": "2022-08-03T09:36:27.607103Z",
     "iopub.status.idle": "2022-08-03T09:36:27.622281Z",
     "shell.execute_reply": "2022-08-03T09:36:27.620683Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028796,
     "end_time": "2022-08-03T09:36:27.625329",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.596533",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "tf.Tensor(\n",
      "[[31]\n",
      " [63]\n",
      " [64]\n",
      " [23]\n",
      " [51]\n",
      " [15]\n",
      " [54]\n",
      " [ 1]\n",
      " [48]\n",
      " [64]\n",
      " [17]\n",
      " [32]\n",
      " [59]\n",
      " [ 5]\n",
      " [40]\n",
      " [44]\n",
      " [ 3]\n",
      " [46]\n",
      " [19]\n",
      " [53]\n",
      " [56]\n",
      " [18]\n",
      " [ 6]\n",
      " [25]\n",
      " [ 8]\n",
      " [ 5]\n",
      " [41]\n",
      " [19]\n",
      " [15]\n",
      " [38]\n",
      " [63]\n",
      " [ 7]\n",
      " [18]\n",
      " [38]\n",
      " [56]\n",
      " [64]\n",
      " [44]\n",
      " [45]\n",
      " [31]\n",
      " [64]\n",
      " [54]\n",
      " [41]\n",
      " [45]\n",
      " [34]\n",
      " [61]\n",
      " [41]\n",
      " [40]\n",
      " [45]\n",
      " [36]\n",
      " [40]\n",
      " [28]\n",
      " [62]\n",
      " [56]\n",
      " [18]\n",
      " [35]\n",
      " [14]\n",
      " [44]\n",
      " [58]\n",
      " [58]\n",
      " [53]\n",
      " [53]\n",
      " [14]\n",
      " [27]\n",
      " [41]\n",
      " [28]\n",
      " [10]\n",
      " [36]\n",
      " [56]\n",
      " [46]\n",
      " [24]\n",
      " [11]\n",
      " [28]\n",
      " [ 0]\n",
      " [62]\n",
      " [24]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [62]\n",
      " [18]\n",
      " [32]\n",
      " [44]\n",
      " [56]\n",
      " [13]\n",
      " [13]\n",
      " [48]\n",
      " [34]\n",
      " [23]\n",
      " [ 1]\n",
      " [ 7]\n",
      " [50]\n",
      " [55]\n",
      " [60]\n",
      " [63]\n",
      " [12]\n",
      " [ 4]\n",
      " [51]\n",
      " [61]\n",
      " [29]\n",
      " [21]\n",
      " [39]], shape=(100, 1), dtype=int64)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[31 63 64 23 51 15 54  1 48 64 17 32 59  5 40 44  3 46 19 53 56 18  6 25\n",
      "  8  5 41 19 15 38 63  7 18 38 56 64 44 45 31 64 54 41 45 34 61 41 40 45\n",
      " 36 40 28 62 56 18 35 14 44 58 58 53 53 14 27 41 28 10 36 56 46 24 11 28\n",
      "  0 62 24  6  6 62 18 32 44 56 13 13 48 34 23  1  7 50 55 60 63 12  4 51\n",
      " 61 29 21 39], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# logits是网络最终的全连接层的输出 还未经过sigmoid或者softmax的概率化  num_samples抽样次数\n",
    "# tf.random.categorical从分类分布中随机抽取num_samples个样本返回下标,随机为了每次生成文本有差异\n",
    "sample_indices = tf.random.categorical(\n",
    "    logits=example_batch_predictions[0], num_samples=1, seed=1)\n",
    "print(sample_indices.shape) # (100, 1)\n",
    "print(sample_indices)  \n",
    "print('-' * 50)\n",
    "sample_indices = tf.squeeze(sample_indices, axis=1)\n",
    "print(sample_indices)  # (100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f37835e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.643980Z",
     "iopub.status.busy": "2022-08-03T09:36:27.643223Z",
     "iopub.status.idle": "2022-08-03T09:36:27.668261Z",
     "shell.execute_reply": "2022-08-03T09:36:27.667323Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035709,
     "end_time": "2022-08-03T09:36:27.670240",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.634531",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3]]\n",
      "[[0 0 0]]\n",
      "[[3 0 0]]\n",
      "[[1 0 0]]\n",
      "[[1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for i in tf.range(5):\n",
    "    # 虽然是随机的，但是还是偏向于概率较大的值\n",
    "    samples = tf.random.categorical([[4.0, 2.0, 2.0, 2.0, 1.0]], 3)\n",
    "    tf.print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b95f830d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.687902Z",
     "iopub.status.busy": "2022-08-03T09:36:27.687095Z",
     "iopub.status.idle": "2022-08-03T09:36:27.696860Z",
     "shell.execute_reply": "2022-08-03T09:36:27.694993Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.021904,
     "end_time": "2022-08-03T09:36:27.700162",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.678258",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \"ward on the journey you shall go.\\n\\nBARNARDINE:\\nI swear I will not die to-day for any man's\\npersuasio\"\n",
      "--------------------------------------------------\n",
      "Output: \"ard on the journey you shall go.\\n\\nBARNARDINE:\\nI swear I will not die to-day for any man's\\npersuasion\"\n",
      "--------------------------------------------------\n",
      "Predictions: \"SyzKmCp jzETu'bf$hGorF,M.'cGCZy-FZrzfgSzpcgVwcbgXbPxrFWBfttooBOcP:XrhL;P\\nxL,,xFTfrAAjVK -lqvy?&mwQIa\"\n"
     ]
    }
   ],
   "source": [
    "print('Input:', repr(''.join(index2char[input_example_batch[0]])))\n",
    "print('-' * 50)\n",
    "print('Output:', repr(''.join(index2char[target_example_batch[0]])))\n",
    "print('-' * 50)\n",
    "print('Predictions:', repr(''.join(index2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f09fc618",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.721895Z",
     "iopub.status.busy": "2022-08-03T09:36:27.720873Z",
     "iopub.status.idle": "2022-08-03T09:36:27.743923Z",
     "shell.execute_reply": "2022-08-03T09:36:27.742390Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036363,
     "end_time": "2022-08-03T09:36:27.746354",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.709991",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "4.174875\n"
     ]
    }
   ],
   "source": [
    "# from_logits是否预期为对数张量。默认情况False下，输出的logits需要经过激活函数的处理再传入接口中\n",
    "# from_logits = False 表示输入进来的y_pred已符合某种分布(即输出层是带softmax激活函数的), 接口只会帮你再进行概率归一化\n",
    "# from_logits = True 表示是原始数据，接口会帮你做softmax后再进行计算\n",
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a47f70a",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T09:36:27.765701Z",
     "iopub.status.busy": "2022-08-03T09:36:27.764707Z",
     "iopub.status.idle": "2022-08-03T10:08:06.426002Z",
     "shell.execute_reply": "2022-08-03T10:08:06.424463Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1898.673398,
     "end_time": "2022-08-03T10:08:06.428840",
     "exception": false,
     "start_time": "2022-08-03T09:36:27.755442",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "172/172 [==============================] - 18s 89ms/step - loss: 2.6431\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 2.2587\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 17s 85ms/step - loss: 1.9799\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 18s 90ms/step - loss: 1.8402\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 17s 89ms/step - loss: 1.7368\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 18s 95ms/step - loss: 1.6613\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.6035\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 18s 86ms/step - loss: 1.5577\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.5218\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 17s 85ms/step - loss: 1.4937\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 18s 90ms/step - loss: 1.4697\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.4480\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 18s 89ms/step - loss: 1.4305\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 17s 89ms/step - loss: 1.4154\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.4006\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 16s 84ms/step - loss: 1.3873\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 18s 86ms/step - loss: 1.3752\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.3650\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.3553\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.3448\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.3349\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 17s 89ms/step - loss: 1.3262\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 17s 82ms/step - loss: 1.3179\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 17s 90ms/step - loss: 1.3093\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 18s 91ms/step - loss: 1.3018\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.2926\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 17s 89ms/step - loss: 1.2865\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.2793\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.2727\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.2654\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.2595\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.2528\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.2460\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.2389\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.2333\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.2259\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.2205\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.2146\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 18s 89ms/step - loss: 1.2109\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.2030\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 17s 85ms/step - loss: 1.1985\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.1943\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 16s 83ms/step - loss: 1.1876\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.1833\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.1782\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.1712\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.1676\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.1649\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 18s 94ms/step - loss: 1.1593\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 16s 84ms/step - loss: 1.1565\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 18s 89ms/step - loss: 1.1509\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 17s 89ms/step - loss: 1.1482\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 18s 90ms/step - loss: 1.1446\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 18s 95ms/step - loss: 1.1402\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.1354\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 18s 90ms/step - loss: 1.1338\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 18s 89ms/step - loss: 1.1319\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.1282\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.1256\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 19s 92ms/step - loss: 1.1224\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.1199\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.1182\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.1160\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 18s 91ms/step - loss: 1.1160\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 19s 97ms/step - loss: 1.1128\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.1105\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 18s 93ms/step - loss: 1.1094\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 17s 90ms/step - loss: 1.1070\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 17s 85ms/step - loss: 1.1068\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 19s 97ms/step - loss: 1.1037\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.1040\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 18s 94ms/step - loss: 1.1017\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 17s 84ms/step - loss: 1.1021\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 19s 92ms/step - loss: 1.1015\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 19s 97ms/step - loss: 1.0986\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 17s 85ms/step - loss: 1.0995\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.0978\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 17s 85ms/step - loss: 1.0967\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 19s 95ms/step - loss: 1.0997\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 17s 86ms/step - loss: 1.0978\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 19s 96ms/step - loss: 1.0960\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 18s 95ms/step - loss: 1.0965\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 17s 84ms/step - loss: 1.0966\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 19s 95ms/step - loss: 1.0956\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 18s 92ms/step - loss: 1.0993\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 18s 95ms/step - loss: 1.0964\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 19s 98ms/step - loss: 1.0980\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.0989\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 19s 101ms/step - loss: 1.0985\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 17s 88ms/step - loss: 1.1007\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 19s 89ms/step - loss: 1.0983\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 19s 100ms/step - loss: 1.0996\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.1002\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 19s 99ms/step - loss: 1.0999\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 18s 90ms/step - loss: 1.1015\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 19s 91ms/step - loss: 1.1040\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 19s 96ms/step - loss: 1.1023\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.1072\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 19s 99ms/step - loss: 1.1054\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 17s 87ms/step - loss: 1.1063\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "output_dir = './text_generation_checkpoints'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "checkpoint_prefix = os.path.join(output_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                                      # 只保存权重的值\n",
    "                                                      save_weights_only=True)\n",
    "epochs = 100\n",
    "history = model.fit(sequence_dataset, epochs = epochs,\n",
    "                    callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9525eded",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T10:08:08.877250Z",
     "iopub.status.busy": "2022-08-03T10:08:08.876777Z",
     "iopub.status.idle": "2022-08-03T10:08:08.885667Z",
     "shell.execute_reply": "2022-08-03T10:08:08.884663Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.372152,
     "end_time": "2022-08-03T10:08:08.892970",
     "exception": false,
     "start_time": "2022-08-03T10:08:07.520818",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./text_generation_checkpoints/ckpt_100\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./text_generation_checkpoints\"\n",
    "print(tf.train.latest_checkpoint(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d368cea4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T10:08:11.032423Z",
     "iopub.status.busy": "2022-08-03T10:08:11.031804Z",
     "iopub.status.idle": "2022-08-03T10:08:11.137081Z",
     "shell.execute_reply": "2022-08-03T10:08:11.135938Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.197973,
     "end_time": "2022-08-03T10:08:11.139604",
     "exception": false,
     "start_time": "2022-08-03T10:08:09.941631",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (1, None, 1024)           1311744   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./text_generation_checkpoints\"\n",
    "model2 = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1) # [1, None]输入一个样本就可以生成文本\n",
    "model2.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "# 文本生成的流程\n",
    "# start ch sequence A, \n",
    "# A -> model -> b  A放入模型后得到b\n",
    "# A.append(b) -> B\n",
    "# B(Ab) -> model -> c\n",
    "# B.append(c) -> C\n",
    "# C(Abc) -> model -> ...\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ae399de",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T10:08:13.283540Z",
     "iopub.status.busy": "2022-08-03T10:08:13.283121Z",
     "iopub.status.idle": "2022-08-03T10:08:13.291537Z",
     "shell.execute_reply": "2022-08-03T10:08:13.290233Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.130876,
     "end_time": "2022-08-03T10:08:13.294132",
     "exception": false,
     "start_time": "2022-08-03T10:08:12.163256",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 文本生成流程\n",
    "def generate_text(model,start_string,num_generate=1000):\n",
    "    input_eval=[char2index[c] for c in start_string]\n",
    "    print(input_eval)\n",
    "    input_eval=tf.expand_dims(input_eval,0)\n",
    "    print(input_eval)\n",
    "    text_generated=[]\n",
    "    # 初始状态 对model进行reset，连续调用的时候使用resets_states()\n",
    "    model.reset_states()\n",
    "    for _ in range(num_generate):\n",
    "        predictions=model(input_eval)\n",
    "        # [batch_size, input_eval_len, vocab_size]\n",
    "        print(predictions.shape)\n",
    "        predictions=tf.squeeze(predictions,0)\n",
    "        # [input_eval_len, vocab_size]\n",
    "        predicted_id=tf.random.categorical( # [input_eval_len, 1]\n",
    "            predictions,num_samples=1)[-1,0].numpy()\n",
    "        print(predicted_id)\n",
    "        # 得到预测id后，放入text_generated\n",
    "        text_generated.append(index2char[predicted_id])\n",
    "        input_eval=tf.expand_dims([predicted_id],0) # [1, 1]-->model-->[1, 1, 65]\n",
    "    return start_string+''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96d01d00",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-08-03T10:08:16.057963Z",
     "iopub.status.busy": "2022-08-03T10:08:16.057507Z",
     "iopub.status.idle": "2022-08-03T10:08:21.889088Z",
     "shell.execute_reply": "2022-08-03T10:08:21.887373Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.327853,
     "end_time": "2022-08-03T10:08:21.892005",
     "exception": false,
     "start_time": "2022-08-03T10:08:14.564152",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 50, 50, 10, 1]\n",
      "tf.Tensor([[13 50 50 10  1]], shape=(1, 5), dtype=int32)\n",
      "(1, 5, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "12\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "60\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "35\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "49\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "14\n",
      "(1, 1, 65)\n",
      "33\n",
      "(1, 1, 65)\n",
      "15\n",
      "(1, 1, 65)\n",
      "23\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "26\n",
      "(1, 1, 65)\n",
      "19\n",
      "(1, 1, 65)\n",
      "20\n",
      "(1, 1, 65)\n",
      "13\n",
      "(1, 1, 65)\n",
      "25\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "25\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "54\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "54\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "30\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "12\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "29\n",
      "(1, 1, 65)\n",
      "33\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "26\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "24\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "38\n",
      "(1, 1, 65)\n",
      "13\n",
      "(1, 1, 65)\n",
      "14\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "20\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "19\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "20\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "60\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "22\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "54\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "7\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "60\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "14\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "27\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "61\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "5\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "13\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "24\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "49\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "12\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "24\n",
      "(1, 1, 65)\n",
      "37\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "12\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "30\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "25\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "27\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "30\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "60\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "5\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "49\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "5\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "25\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "54\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "15\n",
      "(1, 1, 65)\n",
      "24\n",
      "(1, 1, 65)\n",
      "13\n",
      "(1, 1, 65)\n",
      "30\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "26\n",
      "(1, 1, 65)\n",
      "15\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "27\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "61\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "54\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "60\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "54\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "24\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "48\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "28\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "5\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "11\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "44\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "49\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "49\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "45\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "51\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "12\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "26\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "11\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "13\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "63\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "28\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "30\n",
      "(1, 1, 65)\n",
      "16\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "26\n",
      "(1, 1, 65)\n",
      "13\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "37\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "6\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "21\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "61\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "46\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "57\n",
      "(1, 1, 65)\n",
      "58\n",
      "(1, 1, 65)\n",
      "11\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "18\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "56\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "15\n",
      "(1, 1, 65)\n",
      "50\n",
      "(1, 1, 65)\n",
      "39\n",
      "(1, 1, 65)\n",
      "59\n",
      "(1, 1, 65)\n",
      "42\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "52\n",
      "(1, 1, 65)\n",
      "53\n",
      "(1, 1, 65)\n",
      "61\n",
      "(1, 1, 65)\n",
      "8\n",
      "(1, 1, 65)\n",
      "5\n",
      "(1, 1, 65)\n",
      "26\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "32\n",
      "(1, 1, 65)\n",
      "17\n",
      "(1, 1, 65)\n",
      "30\n",
      "(1, 1, 65)\n",
      "10\n",
      "(1, 1, 65)\n",
      "0\n",
      "(1, 1, 65)\n",
      "31\n",
      "(1, 1, 65)\n",
      "47\n",
      "(1, 1, 65)\n",
      "41\n",
      "(1, 1, 65)\n",
      "43\n",
      "(1, 1, 65)\n",
      "1\n",
      "(1, 1, 65)\n",
      "40\n",
      "(1, 1, 65)\n",
      "59\n",
      "All: girl might I?\n",
      "\n",
      "Servant:\n",
      "What hath make me much the army gone.\n",
      "\n",
      "BUCKINGHAM:\n",
      "My lord, thy proport Richmondsm?\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "God I\n",
      "Have mine a\n",
      "nim, Jupricians, early great traitors to our airy it else-courteon\n",
      "To victory,\n",
      "To sent tongue, my benefit you, madly more. But, O, wilt thou hadmedfeer'd are\n",
      "Against the hound\n",
      "Like friends but here?\n",
      "\n",
      "SLY:\n",
      "I should, not? nay, are you, good are Richion to his fly\n",
      "Thomas Margaroon on the noised\n",
      "Intold,\n",
      "Or else and Richard hast thou art out discover'd to the king and me, indeed, lest this is lost made to Elief her, the climents are most,\n",
      "That do ye is to 'em. My mind er triumphant flight.\n",
      "\n",
      "CLARENCE:\n",
      "On sadness follow:\n",
      "This help as leary love.\n",
      "\n",
      "Shepherd:\n",
      "Such\n",
      "s, let us lost the cause and your defending, throne in Saint Lucina unjustishment,\n",
      "Put'st thou rust, and huires by many\n",
      "slain;\n",
      "That I did ficky, being racking me?\n",
      "Nay, I throul by his authority or tear;\n",
      "And shall you nold.\n",
      "\n",
      "PERDINA:\n",
      "Yet it, I will be the east;\n",
      "For Claudion now.'NTESTER:\n",
      "Sice bu\n"
     ]
    }
   ],
   "source": [
    "new_text=generate_text(model2,'All: ')\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1942.539497,
   "end_time": "2022-08-03T10:08:26.627267",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-03T09:36:04.087770",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
