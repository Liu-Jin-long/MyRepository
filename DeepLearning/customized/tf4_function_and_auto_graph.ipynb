{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python函数与tensorflow图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 把python的函数变为图的目的是为了提高程序的运行速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.95021296, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([-0.9959132], shape=(1,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function scaled_elu at 0x000001C4C300FE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(-0.95021296, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(-0.9959132, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function scaled_elu at 0x000001C4C300FE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([-0.9959132], shape=(1,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "True\n",
      "<function scaled_elu at 0x000001C4C300FE50>\n",
      "<tensorflow.python.eager.def_function.Function object at 0x000001C4CB6C7550>\n"
     ]
    }
   ],
   "source": [
    "# tf.function and auto-graph\n",
    "# 实现一下elu激活函数\n",
    "def scaled_elu(z, scale=1., alpha=1.):\n",
    "    # z >= 0 ? scale * z:scale * alpha * tf.nn.elu\n",
    "    is_positive = tf.greater_equal(z, 0.)\n",
    "    # return scale * tf.where(is_positive, z, alpha * tf.nn.elu(z))\n",
    "    return scale * tf.where(is_positive, z, alpha * (tf.math.exp(z) - 1))\n",
    "\n",
    "\n",
    "print(scaled_elu(tf.constant(-3.)))\n",
    "print('-' * 50)\n",
    "print(scaled_elu(tf.constant([-3. - 2.5])))\n",
    "print('-' * 50)\n",
    "# 通过tf.function可以把python的函数变为图实现的函数\n",
    "scaled_elu_tf = tf.function(scaled_elu)\n",
    "print(scaled_elu_tf(tf.constant(-3.)))\n",
    "print('-' * 50)\n",
    "print(scaled_elu_tf(tf.constant(-5.5)))\n",
    "print(scaled_elu_tf(tf.constant([-3. - 2.5])))\n",
    "print('-' * 50)\n",
    "# 原python函数\n",
    "print(scaled_elu_tf.python_function is scaled_elu) # True\n",
    "print(scaled_elu)\n",
    "print(scaled_elu_tf)  # 执行效率相对较高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # 测试\n",
    "# %timeit scaled_elu(tf.random.normal((1000, 1000)))\n",
    "# %timeit scaled_elu_tf(tf.random.normal((1000, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.eager.def_function.Function object at 0x000001C4CB6CEF10>\n",
      "<class 'tensorflow.python.eager.def_function.Function'>\n",
      "--------------------------------------------------\n",
      "tf.Tensor(1.9999981, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 通过装饰器把python函数变为图\n",
    "@tf.function\n",
    "def converge_to_2(n_iters):\n",
    "    total = tf.constant(0.)\n",
    "    increment = tf.constant(1.)\n",
    "    for _ in range(n_iters):\n",
    "        total += increment\n",
    "        increment /= 2.\n",
    "    return total\n",
    "\n",
    "\n",
    "print(converge_to_2)\n",
    "print(type(converge_to_2)) # <class 'tensorflow.python.eager.def_function.Function'>\n",
    "print('-' * 50)\n",
    "print(converge_to_2(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__scaled_elu(z, scale=None, alpha=None):\n",
       "    with ag__.FunctionScope('scaled_elu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "        is_positive = ag__.converted_call(ag__.ld(tf).greater_equal, (ag__.ld(z), 0.0), None, fscope)\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(scale) * ag__.converted_call(ag__.ld(tf).where, (ag__.ld(is_positive), ag__.ld(z), ag__.ld(alpha) * (ag__.converted_call(ag__.ld(tf).math.exp, (ag__.ld(z),), None, fscope) - 1)), None, fscope)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 查看tf图的代码\n",
    "def display_tf_code(func):\n",
    "    code = tf.autograph.to_code(func)\n",
    "    from IPython.display import display, Markdown\n",
    "    display(Markdown(f'```python\\n{code}\\n```'))\n",
    "\n",
    "# 传python函数,返回tf图的代码\n",
    "print(display_tf_code(scaled_elu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.eager.def_function.Function'>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__converge_to(n_iters):\n",
       "    with ag__.FunctionScope('converge_to_2', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "        total = ag__.converted_call(ag__.ld(tf).constant, (0.0,), None, fscope)\n",
       "        increment = ag__.converted_call(ag__.ld(tf).constant, (1.0,), None, fscope)\n",
       "\n",
       "        def get_state():\n",
       "            return (total, increment)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal increment, total\n",
       "            (total, increment) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal increment, total\n",
       "            _ = itr\n",
       "            total = ag__.ld(total)\n",
       "            total += increment\n",
       "            increment = ag__.ld(increment)\n",
       "            increment /= 2.0\n",
       "        _ = ag__.Undefined('_')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(n_iters),), None, fscope), None, loop_body, get_state, set_state, ('total', 'increment'), {'iterate_names': '_'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(total)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(display_tf_code(converge_to_2)) # ConversionError\n",
    "print(type(converge_to_2)) # <class 'tensorflow.python.eager.def_function.Function'>\n",
    "print(display_tf_code(converge_to_2.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#tf要把变量定义在函数外面，不能放里边\n",
    "var = tf.Variable(0.)\n",
    "@tf.function\n",
    "def add_10():\n",
    "     # var = tf.Variable(0.)\n",
    "    return var.assign_add(10)\n",
    "\n",
    "\n",
    "print(add_10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1.  8. 27.], shape=(3,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([ 1  8 27], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def cube(z):\n",
    "    return tf.pow(z, 3)\n",
    "\n",
    "\n",
    "try:\n",
    "    print(cube(tf.constant([1.0, 2.0, 3.0])))\n",
    "except ValueError as ex:\n",
    "    print(ex)\n",
    "print('-' * 50)\n",
    "print(cube(tf.constant([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None,), dtype=tf.int32, name='x')).\n",
      "--------------------------------------------------\n",
      "tf.Tensor([ 1  8 27], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# python泛型设计 通过input_signature加类型限制可以防止调错\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.int32, name='x')])\n",
    "def cube(z):\n",
    "    return tf.pow(z, 3)\n",
    "\n",
    "\n",
    "try:\n",
    "    print(cube(tf.constant([1.0, 2.0, 3.0])))\n",
    "except ValueError as ex:\n",
    "    print(ex)\n",
    "print('-' * 50)\n",
    "print(cube(tf.constant([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction cube(z)\n",
      "  Args:\n",
      "    z: int32 Tensor, shape=(None,)\n",
      "  Returns:\n",
      "    int32 Tensor, shape=(None,)\n",
      "--------------------------------------------------\n",
      "<tensorflow.python.eager.def_function.Function object at 0x000001C4CC0FB520>\n",
      "tf.Tensor([ 1  8 27], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "cube_func_int32 = cube.get_concrete_function(tf.TensorSpec([None], tf.int32))\n",
    "print(cube_func_int32)\n",
    "print('-' * 50)\n",
    "print(cube)\n",
    "try:\n",
    "    print(cube_func_int32(tf.constant([1, 2, 3])))\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943965814544\n",
      "1943965814544\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# print(cube_func_int32 is cube.get_concrete_function())\n",
    "print(id(cube.get_concrete_function(tf.TensorSpec([None], tf.int32))))\n",
    "print(id(cube_func_int32)) # 原来函数和新生成的函数一致\n",
    "print(cube_func_int32 is cube.get_concrete_function(tf.TensorSpec([None], tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction cube(z)\n",
      "  Args:\n",
      "    z: int32 Tensor, shape=(None,)\n",
      "  Returns:\n",
      "    int32 Tensor, shape=(None,)\n",
      "FuncGraph(name=cube, id=1943965811280)\n",
      "--------------------------------------------------\n",
      "[<tf.Operation 'x' type=Placeholder>, <tf.Operation 'Pow/y' type=Const>, <tf.Operation 'Pow' type=Pow>, <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "print(cube_func_int32)\n",
    "print(cube_func_int32.graph)\n",
    "print('-' * 50)\n",
    "# 图的操作\n",
    "print(cube_func_int32.graph.get_operations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"x\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"_user_specified_name\"\n",
      "  value {\n",
      "    s: \"x\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pow_op = cube_func_int32.graph.get_operations()[0]\n",
    "print(pow_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "--------------------------------------------------\n",
      "[<tf.Tensor 'x:0' shape=(None,) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "print(list(pow_op.inputs))\n",
    "print('-' * 50)\n",
    "print(list(pow_op.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'z' refers to an Operation not in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [48]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Placeholder用来放输入的地方，2.0中不需要，图中依然保留了\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcube_func_int32\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_operation_by_name\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mz\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4080\u001B[0m, in \u001B[0;36mGraph.get_operation_by_name\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   4077\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(name, six\u001B[38;5;241m.\u001B[39mstring_types):\n\u001B[0;32m   4078\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOperation names are strings (or similar), not \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   4079\u001B[0m                   \u001B[38;5;28mtype\u001B[39m(name)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m-> 4080\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_graph_element\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_operation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3952\u001B[0m, in \u001B[0;36mGraph.as_graph_element\u001B[1;34m(self, obj, allow_tensor, allow_operation)\u001B[0m\n\u001B[0;32m   3949\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001B[0;32m   3951\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m-> 3952\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_as_graph_element_locked\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_operation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4011\u001B[0m, in \u001B[0;36mGraph._as_graph_element_locked\u001B[1;34m(self, obj, allow_tensor, allow_operation)\u001B[0m\n\u001B[0;32m   4008\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m name \u001B[38;5;129;01mand\u001B[39;00m allow_operation:\n\u001B[0;32m   4009\u001B[0m   \u001B[38;5;66;03m# Looks like an Operation name and can be an Operation.\u001B[39;00m\n\u001B[0;32m   4010\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nodes_by_name:\n\u001B[1;32m-> 4011\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe name \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m refers to an Operation not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4012\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mrepr\u001B[39m(name))\n\u001B[0;32m   4013\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nodes_by_name[name]\n\u001B[0;32m   4015\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m name \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_operation:\n\u001B[0;32m   4016\u001B[0m   \u001B[38;5;66;03m# Looks like an Operation name but can't be an Operation.\u001B[39;00m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"The name 'z' refers to an Operation not in the graph.\""
     ]
    }
   ],
   "source": [
    "# Placeholder用来放输入的地方，2.0中不需要，图中依然保留了\n",
    "print(cube_func_int32.graph.get_operation_by_name(\"z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'z:0' refers to a Tensor which does not exist. The operation, 'z', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [50]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcube_func_int32\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tensor_by_name\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mz:0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4128\u001B[0m, in \u001B[0;36mGraph.get_tensor_by_name\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   4125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(name, six\u001B[38;5;241m.\u001B[39mstring_types):\n\u001B[0;32m   4126\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensor names are strings (or similar), not \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   4127\u001B[0m                   \u001B[38;5;28mtype\u001B[39m(name)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m-> 4128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_graph_element\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_operation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3952\u001B[0m, in \u001B[0;36mGraph.as_graph_element\u001B[1;34m(self, obj, allow_tensor, allow_operation)\u001B[0m\n\u001B[0;32m   3949\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001B[0;32m   3951\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m-> 3952\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_as_graph_element_locked\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_operation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3992\u001B[0m, in \u001B[0;36mGraph._as_graph_element_locked\u001B[1;34m(self, obj, allow_tensor, allow_operation)\u001B[0m\n\u001B[0;32m   3990\u001B[0m   op \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nodes_by_name[op_name]\n\u001B[0;32m   3991\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3992\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe name \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m refers to a Tensor which does not \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3993\u001B[0m                  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexist. The operation, \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, does not exist in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3994\u001B[0m                  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mrepr\u001B[39m(name), \u001B[38;5;28mrepr\u001B[39m(op_name)))\n\u001B[0;32m   3995\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   3996\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39moutputs[out_n]\n",
      "\u001B[1;31mKeyError\u001B[0m: \"The name 'z:0' refers to a Tensor which does not exist. The operation, 'z', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "print(cube_func_int32.graph.get_tensor_by_name(\"z:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 图的信息\n",
    "print(cube_func_int32.graph.as_graph_def())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}