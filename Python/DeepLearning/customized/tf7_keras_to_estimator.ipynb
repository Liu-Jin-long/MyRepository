{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "sys.version_info(major=3, minor=9, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.5.2\n",
      "numpy 1.23.0\n",
      "pandas 1.4.3\n",
      "sklearn 1.1.1\n",
      "tensorflow 2.9.1\n",
      "keras.api._v2.keras 2.9.0\n"
     ]
    }
   ],
   "source": [
    "# 估计器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "--------------------------------------------------\n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "--------------------------------------------------\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "--------------------------------------------------\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 提取目标值\n",
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "print(train_df.head())\n",
    "print('-' * 50)\n",
    "print(eval_df.head())\n",
    "print('-' * 50)\n",
    "print(y_train.head())\n",
    "print('-' * 50)\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age  n_siblings_spouses       parch        fare\n",
      "count  627.000000          627.000000  627.000000  627.000000\n",
      "mean    29.631308            0.545455    0.379585   34.385399\n",
      "std     12.511818            1.151090    0.792999   54.597730\n",
      "min      0.750000            0.000000    0.000000    0.000000\n",
      "25%     23.000000            0.000000    0.000000    7.895800\n",
      "50%     28.000000            0.000000    0.000000   15.045800\n",
      "75%     35.000000            1.000000    0.000000   31.387500\n",
      "max     80.000000            8.000000    5.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "0.75     1.000000\n",
      "0.83     1.000000\n",
      "1.00     0.333333\n",
      "2.00     0.333333\n",
      "3.00     1.000000\n",
      "           ...   \n",
      "66.00    0.000000\n",
      "70.00    0.000000\n",
      "70.50    0.000000\n",
      "71.00    0.000000\n",
      "80.00    1.000000\n",
      "Name: survived, Length: 76, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([train_df, y_train], axis=1).groupby('age').survived.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n",
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# 离散型特征\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "# 连续型特征\n",
    "numeric_columns = ['age', 'fare']\n",
    "# 离散特征处理\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        # indicator_column做one-hot编码\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "# 离散特征处理\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))\n",
    "# 特征类别\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': 0        male\n",
      "1      female\n",
      "2      female\n",
      "3      female\n",
      "4        male\n",
      "        ...  \n",
      "622      male\n",
      "623      male\n",
      "624    female\n",
      "625    female\n",
      "626      male\n",
      "Name: sex, Length: 627, dtype: object, 'age': 0      22.0\n",
      "1      38.0\n",
      "2      26.0\n",
      "3      35.0\n",
      "4      28.0\n",
      "       ... \n",
      "622    28.0\n",
      "623    25.0\n",
      "624    19.0\n",
      "625    28.0\n",
      "626    32.0\n",
      "Name: age, Length: 627, dtype: float64, 'n_siblings_spouses': 0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "622    0\n",
      "623    0\n",
      "624    0\n",
      "625    1\n",
      "626    0\n",
      "Name: n_siblings_spouses, Length: 627, dtype: int64, 'parch': 0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "622    0\n",
      "623    0\n",
      "624    0\n",
      "625    2\n",
      "626    0\n",
      "Name: parch, Length: 627, dtype: int64, 'fare': 0       7.2500\n",
      "1      71.2833\n",
      "2       7.9250\n",
      "3      53.1000\n",
      "4       8.4583\n",
      "        ...   \n",
      "622    10.5000\n",
      "623     7.0500\n",
      "624    30.0000\n",
      "625    23.4500\n",
      "626     7.7500\n",
      "Name: fare, Length: 627, dtype: float64, 'class': 0       Third\n",
      "1       First\n",
      "2       Third\n",
      "3       First\n",
      "4       Third\n",
      "        ...  \n",
      "622    Second\n",
      "623     Third\n",
      "624     First\n",
      "625     Third\n",
      "626     Third\n",
      "Name: class, Length: 627, dtype: object, 'deck': 0      unknown\n",
      "1            C\n",
      "2      unknown\n",
      "3            C\n",
      "4      unknown\n",
      "        ...   \n",
      "622    unknown\n",
      "623    unknown\n",
      "624          B\n",
      "625    unknown\n",
      "626    unknown\n",
      "Name: deck, Length: 627, dtype: object, 'embark_town': 0      Southampton\n",
      "1        Cherbourg\n",
      "2      Southampton\n",
      "3      Southampton\n",
      "4       Queenstown\n",
      "          ...     \n",
      "622    Southampton\n",
      "623    Southampton\n",
      "624    Southampton\n",
      "625    Southampton\n",
      "626     Queenstown\n",
      "Name: embark_town, Length: 627, dtype: object, 'alone': 0      n\n",
      "1      n\n",
      "2      y\n",
      "3      n\n",
      "4      y\n",
      "      ..\n",
      "622    y\n",
      "623    y\n",
      "624    y\n",
      "625    n\n",
      "626    y\n",
      "Name: alone, Length: 627, dtype: object}\n"
     ]
    }
   ],
   "source": [
    "print(dict(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "622    0\n",
      "623    0\n",
      "624    1\n",
      "625    0\n",
      "626    0\n",
      "Name: survived, Length: 627, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs=10, shuffle=True, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices((data_df, label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "--------------------------------------------------\n",
      "[[50.]\n",
      " [34.]\n",
      " [19.]\n",
      " [28.]\n",
      " [28.]]\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())\n",
    "##%\n",
    "print(feature_columns)\n",
    "print('-' * 50)\n",
    "# A layer that produces a dense Tensor based on given feature_columns\n",
    "for x, y in train_dataset.take(1):\n",
    "    # 特征类型\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    # DenseFeatures进行转换\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x))  # 变为one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[18.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  20.2125  1.      0.      0.      0.      0.      0.      0.      0.\n",
      "   1.      0.      0.      0.      0.      1.      0.    ]\n",
      " [27.      0.      1.      0.      1.      0.      0.      0.      0.\n",
      "   0.      0.      1.      0.      0.      0.      1.      0.      0.\n",
      "  76.7292  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [19.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.8958  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [28.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
      "  23.25    0.      0.      0.      0.      1.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [21.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
      "   7.75    0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]], shape=(5, 34), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DenseFeatures可以直接将非数值类型特征转为数值类型特征\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),  # 传入feature_columns，直接处理所有特征\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax'), ])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=0.005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'sex': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>, 'parch': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int64>, 'fare': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'class': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'deck': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'embark_town': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'alone': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'sex': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>, 'parch': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int64>, 'fare': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'class': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'deck': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'embark_town': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'alone': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      " 1/19 [>.............................] - ETA: 8s - loss: 1.7972 - accuracy: 0.5312WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'sex': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>, 'parch': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int64>, 'fare': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'class': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'deck': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'embark_town': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'alone': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "19/19 [==============================] - 1s 14ms/step - loss: 1.4186 - accuracy: 0.5987 - val_loss: 0.8347 - val_accuracy: 0.6289\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.6168 - val_loss: 0.7428 - val_accuracy: 0.6641\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.6332 - val_loss: 0.6139 - val_accuracy: 0.6914\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6793 - val_loss: 0.6402 - val_accuracy: 0.6641\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6760 - val_loss: 0.6413 - val_accuracy: 0.6484\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.6809 - val_loss: 0.6178 - val_accuracy: 0.6680\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.6398 - val_loss: 0.6002 - val_accuracy: 0.6758\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6793 - val_loss: 0.5968 - val_accuracy: 0.6992\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6760 - val_loss: 0.6038 - val_accuracy: 0.7109\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6859 - val_loss: 0.6040 - val_accuracy: 0.6719\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.7007 - val_loss: 0.5818 - val_accuracy: 0.7070\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6645 - val_loss: 0.6768 - val_accuracy: 0.6367\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6990 - val_loss: 0.5831 - val_accuracy: 0.7070\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6793 - val_loss: 0.5656 - val_accuracy: 0.7070\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7171 - val_loss: 0.5636 - val_accuracy: 0.7031\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6990 - val_loss: 0.5857 - val_accuracy: 0.6875\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.6891 - val_loss: 0.5955 - val_accuracy: 0.6953\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7072 - val_loss: 0.5803 - val_accuracy: 0.7031\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7072 - val_loss: 0.5684 - val_accuracy: 0.7148\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7039 - val_loss: 0.5829 - val_accuracy: 0.7031\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7105 - val_loss: 0.5647 - val_accuracy: 0.7109\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7155 - val_loss: 0.6130 - val_accuracy: 0.6445\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.6990 - val_loss: 0.5565 - val_accuracy: 0.7031\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6990 - val_loss: 0.5473 - val_accuracy: 0.7070\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7039 - val_loss: 0.5654 - val_accuracy: 0.7109\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7122 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7467 - val_loss: 0.5632 - val_accuracy: 0.7031\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7023 - val_loss: 0.5700 - val_accuracy: 0.6953\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7122 - val_loss: 0.5443 - val_accuracy: 0.7266\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7286 - val_loss: 0.5430 - val_accuracy: 0.7305\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7336 - val_loss: 0.5946 - val_accuracy: 0.6484\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7319 - val_loss: 0.5391 - val_accuracy: 0.7461\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7467 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7401 - val_loss: 0.5761 - val_accuracy: 0.7109\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7204 - val_loss: 0.5565 - val_accuracy: 0.7227\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7368 - val_loss: 0.5317 - val_accuracy: 0.7109\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7418 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7467 - val_loss: 0.5372 - val_accuracy: 0.7383\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7286 - val_loss: 0.5699 - val_accuracy: 0.6641\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7467 - val_loss: 0.5287 - val_accuracy: 0.7227\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7105 - val_loss: 0.5435 - val_accuracy: 0.7148\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7484 - val_loss: 0.5256 - val_accuracy: 0.7305\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.5284 - val_accuracy: 0.7109\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7516 - val_loss: 0.5212 - val_accuracy: 0.7305\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7303 - val_loss: 0.5246 - val_accuracy: 0.7266\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7549 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7434 - val_loss: 0.5422 - val_accuracy: 0.7227\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7220 - val_loss: 0.5268 - val_accuracy: 0.7539\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7434 - val_loss: 0.5138 - val_accuracy: 0.7305\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7714 - val_loss: 0.5348 - val_accuracy: 0.7227\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7385 - val_loss: 0.5130 - val_accuracy: 0.7578\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7401 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7681 - val_loss: 0.5165 - val_accuracy: 0.7383\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7253 - val_loss: 0.6100 - val_accuracy: 0.6641\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7237 - val_loss: 0.5143 - val_accuracy: 0.7383\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7368 - val_loss: 0.5313 - val_accuracy: 0.7227\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7697 - val_loss: 0.5655 - val_accuracy: 0.7070\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7336 - val_loss: 0.5199 - val_accuracy: 0.7305\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7204 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7566 - val_loss: 0.5080 - val_accuracy: 0.7383\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7418 - val_loss: 0.5225 - val_accuracy: 0.7266\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7549 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7155 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7730 - val_loss: 0.5194 - val_accuracy: 0.7305\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7714 - val_loss: 0.7653 - val_accuracy: 0.6289\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7467 - val_loss: 0.5395 - val_accuracy: 0.7305\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7780 - val_loss: 0.6117 - val_accuracy: 0.6484\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7204 - val_loss: 0.5254 - val_accuracy: 0.7383\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7796 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7944 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7730 - val_loss: 0.5046 - val_accuracy: 0.7695\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7188 - val_loss: 0.5038 - val_accuracy: 0.7734\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7566 - val_loss: 0.4958 - val_accuracy: 0.7617\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7204 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7763 - val_loss: 0.5073 - val_accuracy: 0.7539\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7714 - val_loss: 0.5208 - val_accuracy: 0.7539\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7796 - val_loss: 0.5538 - val_accuracy: 0.7109\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7418 - val_loss: 0.5408 - val_accuracy: 0.7305\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7845 - val_loss: 0.5243 - val_accuracy: 0.7383\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7418 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7796 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7319 - val_loss: 0.4921 - val_accuracy: 0.7695\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7664 - val_loss: 0.5766 - val_accuracy: 0.7109\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7928 - val_loss: 0.4885 - val_accuracy: 0.7812\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7730 - val_loss: 0.5353 - val_accuracy: 0.7227\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7895 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7845 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7434 - val_loss: 0.5039 - val_accuracy: 0.7695\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7695\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7352 - val_loss: 0.4917 - val_accuracy: 0.7539\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7582 - val_loss: 0.6001 - val_accuracy: 0.7188\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7763 - val_loss: 0.5000 - val_accuracy: 0.7578\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7829 - val_loss: 0.4993 - val_accuracy: 0.7539\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.8026 - val_loss: 0.4873 - val_accuracy: 0.7422\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7418 - val_loss: 0.4982 - val_accuracy: 0.7539\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7895 - val_loss: 0.4835 - val_accuracy: 0.7734\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7648 - val_loss: 0.5756 - val_accuracy: 0.7109\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8125 - val_loss: 0.4898 - val_accuracy: 0.7539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7796 - val_loss: 0.5033 - val_accuracy: 0.7422\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7829 - val_loss: 0.4838 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# 第一种方式 model.fit()\n",
    "train_dataset = make_dataset(train_df, y_train, epochs=100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs=100, shuffle=False)  #验证集\n",
    "# train_dataset里边包含特征和目标，feature_columns只处理特征\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=eval_dataset,\n",
    "                    steps_per_epoch=19,\n",
    "                    validation_steps=8,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\MYTEMP~1\\tmpl4qth4ge\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\MYTEMP~1\\\\tmpl4qth4ge', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python39\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [46]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m estimator \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mmodel_to_estimator(model)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# input_fn输入必须是函数\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmake_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001B[0m, in \u001B[0;36mEstimator.train\u001B[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001B[0m\n\u001B[0;32m    357\u001B[0m hooks\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001B[0;32m    359\u001B[0m saving_listeners \u001B[38;5;241m=\u001B[39m _check_listeners_type(saving_listeners)\n\u001B[1;32m--> 360\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaving_listeners\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    361\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss for final step: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, loss)\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1186\u001B[0m, in \u001B[0;36mEstimator._train_model\u001B[1;34m(self, input_fn, hooks, saving_listeners)\u001B[0m\n\u001B[0;32m   1184\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1186\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_model_default\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaving_listeners\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1214\u001B[0m, in \u001B[0;36mEstimator._train_model_default\u001B[1;34m(self, input_fn, hooks, saving_listeners)\u001B[0m\n\u001B[0;32m   1211\u001B[0m features, labels, input_hooks \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1212\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_features_and_labels_from_input_fn(input_fn, ModeKeys\u001B[38;5;241m.\u001B[39mTRAIN))\n\u001B[0;32m   1213\u001B[0m worker_hooks\u001B[38;5;241m.\u001B[39mextend(input_hooks)\n\u001B[1;32m-> 1214\u001B[0m estimator_spec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_model_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1215\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m global_step_tensor \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mget_global_step(g)\n\u001B[0;32m   1217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001B[0;32m   1218\u001B[0m                                        hooks, global_step_tensor,\n\u001B[0;32m   1219\u001B[0m                                        saving_listeners)\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1174\u001B[0m, in \u001B[0;36mEstimator._call_model_fn\u001B[1;34m(self, features, labels, mode, config)\u001B[0m\n\u001B[0;32m   1171\u001B[0m   kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m config\n\u001B[0;32m   1173\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCalling model_fn.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1174\u001B[0m model_fn_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model_fn(features\u001B[38;5;241m=\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1175\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDone calling model_fn.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model_fn_results, model_fn_lib\u001B[38;5;241m.\u001B[39mEstimatorSpec):\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras_lib.py:322\u001B[0m, in \u001B[0;36m_create_keras_model_fn.<locals>.model_fn\u001B[1;34m(features, labels, mode)\u001B[0m\n\u001B[0;32m    320\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodel_fn\u001B[39m(features, labels, mode):\n\u001B[0;32m    321\u001B[0m   \u001B[38;5;124;03m\"\"\"model_fn for keras Estimator.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 322\u001B[0m   model \u001B[38;5;241m=\u001B[39m \u001B[43m_clone_and_build_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[43m      \u001B[49m\u001B[43mkeras_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeras_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    326\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    327\u001B[0m \u001B[43m      \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m      \u001B[49m\u001B[43moptimizer_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    329\u001B[0m   model_output_names \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    330\u001B[0m   \u001B[38;5;66;03m# We need to make sure that the output names of the last layer in the model\u001B[39;00m\n\u001B[0;32m    331\u001B[0m   \u001B[38;5;66;03m# is the same for each of the cloned models. This is required for mirrored\u001B[39;00m\n\u001B[0;32m    332\u001B[0m   \u001B[38;5;66;03m# strategy when we call regroup.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras_lib.py:229\u001B[0m, in \u001B[0;36m_clone_and_build_model\u001B[1;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001B[0m\n\u001B[0;32m    226\u001B[0m   global_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mget_or_create_global_step()\n\u001B[0;32m    227\u001B[0m   tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv2\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mtrack_variable(global_step)\n\u001B[1;32m--> 229\u001B[0m clone \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__internal__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclone_and_build_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeras_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompile_clone\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompile_clone\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_place_reset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkeras_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_is_graph_network\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mglobal_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight_tensors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    240\u001B[0m   sample_weight_tensors \u001B[38;5;241m=\u001B[39m standardize_sample_weights(\n\u001B[0;32m    241\u001B[0m       sample_weight_tensors, clone\u001B[38;5;241m.\u001B[39moutput_names)\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\keras\\models\\cloning.py:674\u001B[0m, in \u001B[0;36mclone_and_build_model\u001B[1;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001B[0m\n\u001B[0;32m    672\u001B[0m   clone \u001B[38;5;241m=\u001B[39m clone_model(model, input_tensors\u001B[38;5;241m=\u001B[39minput_tensors)\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, Sequential):\n\u001B[1;32m--> 674\u001B[0m   clone \u001B[38;5;241m=\u001B[39m \u001B[43mclone_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    675\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m clone\u001B[38;5;241m.\u001B[39m_is_graph_network \u001B[38;5;129;01mand\u001B[39;00m model\u001B[38;5;241m.\u001B[39m_build_input_shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mexecuting_eagerly_outside_functions():\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\keras\\models\\cloning.py:445\u001B[0m, in \u001B[0;36mclone_model\u001B[1;34m(model, input_tensors, clone_function)\u001B[0m\n\u001B[0;32m    442\u001B[0m   clone_function \u001B[38;5;241m=\u001B[39m _clone_layer\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, Sequential):\n\u001B[1;32m--> 445\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_clone_sequential_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    446\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclone_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    448\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _clone_functional_model(\n\u001B[0;32m    449\u001B[0m       model, input_tensors\u001B[38;5;241m=\u001B[39minput_tensors, layer_fn\u001B[38;5;241m=\u001B[39mclone_function)\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\keras\\models\\cloning.py:338\u001B[0m, in \u001B[0;36m_clone_sequential_model\u001B[1;34m(model, input_tensors, layer_fn)\u001B[0m\n\u001B[0;32m    336\u001B[0m   input_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(input_tensors)\n\u001B[0;32m    337\u001B[0m x \u001B[38;5;241m=\u001B[39m generic_utils\u001B[38;5;241m.\u001B[39mto_list(input_tensors)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_keras_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    339\u001B[0m   origin_layer \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39m_keras_history\u001B[38;5;241m.\u001B[39mlayer\n\u001B[0;32m    340\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(origin_layer, InputLayer):\n",
      "File \u001B[1;32mD:\\Python39\\lib\\site-packages\\keras\\backend.py:1297\u001B[0m, in \u001B[0;36mis_keras_tensor\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;124;03m\"\"\"Returns whether `x` is a Keras tensor.\u001B[39;00m\n\u001B[0;32m   1253\u001B[0m \n\u001B[0;32m   1254\u001B[0m \u001B[38;5;124;03mA \"Keras tensor\" is a tensor that was returned by a Keras layer,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1291\u001B[0m \n\u001B[0;32m   1292\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x,\n\u001B[0;32m   1294\u001B[0m                   (tf\u001B[38;5;241m.\u001B[39mTensor, tf\u001B[38;5;241m.\u001B[39mVariable,\n\u001B[0;32m   1295\u001B[0m                    tf\u001B[38;5;241m.\u001B[39mSparseTensor, tf\u001B[38;5;241m.\u001B[39mRaggedTensor,\n\u001B[0;32m   1296\u001B[0m                    keras_tensor\u001B[38;5;241m.\u001B[39mKerasTensor)):\n\u001B[1;32m-> 1297\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnexpectedly found an instance of type `\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(x)) \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m   1298\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`. Expected a symbolic tensor instance.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mexecuting_eagerly_outside_functions():\n\u001B[0;32m   1300\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, keras_tensor\u001B[38;5;241m.\u001B[39mKerasTensor)\n",
      "\u001B[1;31mValueError\u001B[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "# 第二种方式 model->estimator->train\n",
    "# TensorFlow的已知bug未修复\n",
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# input_fn输入必须是函数\n",
    "estimator.train(input_fn=lambda: make_dataset(train_df, y_train, epochs=100), steps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}