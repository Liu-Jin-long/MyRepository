{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==1.13.1","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:46:36.653876Z","iopub.execute_input":"2022-07-29T01:46:36.654373Z","iopub.status.idle":"2022-07-29T01:47:21.159198Z","shell.execute_reply.started":"2022-07-29T01:46:36.654270Z","shell.execute_reply":"2022-07-29T01:47:21.158109Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==1.13.1\n  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.19.4)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\nCollecting tensorboard<1.14.0,>=1.13.0\n  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.2)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.21.6)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.43.0)\nCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.6/367.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.37.1)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.4.0)\nCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.16.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.7.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.7)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (2.1.2)\nRequirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.12.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.0)\nInstalling collected packages: tensorflow-estimator, astor, keras-applications, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.4\n    Uninstalling tensorflow-2.6.4:\n      Successfully uninstalled tensorflow-2.6.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.13.1 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorflow<3.0,>=1.15.0, but you have tensorflow 1.13.1 which is incompatible.\npytorch-lightning 1.6.5 requires tensorboard>=2.2.0, but you have tensorboard 1.13.1 which is incompatible.\nexplainable-ai-sdk 1.3.3 requires tensorflow>=1.15.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport time\nimport pickle\nimport numpy as np\n\nprint(tf.__version__)\nCIFAR_DIR = '/kaggle/input/cifar10/cifar-10-batches-py'\nprint(os.listdir(CIFAR_DIR))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T01:47:21.162358Z","iopub.execute_input":"2022-07-29T01:47:21.162726Z","iopub.status.idle":"2022-07-29T01:47:22.263980Z","shell.execute_reply.started":"2022-07-29T01:47:21.162687Z","shell.execute_reply":"2022-07-29T01:47:22.262991Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"},{"name":"stdout","text":"1.13.1\n['data_batch_1', 'data_batch_2', 'batches.meta', 'test_batch', 'data_batch_3', 'data_batch_5', 'data_batch_4', 'readme.html']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_filenames = [os.path.join(CIFAR_DIR, f'data_batch_{i}') for i in range(1,6)]\ntest_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\nprint(train_filenames)\nprint(test_filenames)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:22.265590Z","iopub.execute_input":"2022-07-29T01:47:22.265938Z","iopub.status.idle":"2022-07-29T01:47:22.272328Z","shell.execute_reply.started":"2022-07-29T01:47:22.265903Z","shell.execute_reply":"2022-07-29T01:47:22.271314Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['/kaggle/input/cifar10/cifar-10-batches-py/data_batch_1', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_2', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_3', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_4', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_5']\n['/kaggle/input/cifar10/cifar-10-batches-py/test_batch']\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(filename):\n    \"\"\"前面是图片特征，后面是图片分类标签\"\"\"\n    with open(filename, 'rb') as f:\n        data = pickle.load(f, encoding='bytes')\n        return data[b'data'], data[b'labels']\n\n\n# tensorflow.Dataset\nclass CifarData:\n    def __init__(self, filenames, need_shuffle):\n        all_data = []\n        all_lables = []\n        for filename in filenames:\n            data, labels = load_data(filename)\n            all_data.append(data)  # all_data[0]列表中10000个存有(32*32*3=)3072个数的一维列表c\n            all_lables.append(labels)  # all_data[0]列表中10000个标签值\n        self._data = np.vstack(all_data)  # 垂直方向沿轴2堆叠 变为ndarray\n        self._data = self._data / 127.5 - 1  # 归一化到范围[-1,1]\n        self._lables = np.hstack(all_lables)  # 一维列表变成ndarray\n        print(self._data.shape)  # (50000, 3072) 每一张图像展平后的结果\n        print(self._lables.shape)\n        print(self._lables[:5])\n\n        self._num_samples = self._data.shape[0]  # 样本数\n        self._need_shuffle = need_shuffle  # 进行洗牌随机\n        self._indicator = 0\n        if self._need_shuffle:\n            self._shuffle_data()\n\n    def _shuffle_data(self):\n        # 通过随机排列下标进行随机样本\n        p = np.random.permutation(self._num_samples)  # 变成随机下标\n        self._data = self._data[p]\n        self._lables = self._lables[p]\n\n    def next_batch(self, batch_size):\n        \"\"\"return batch_size samples as a batch.\"\"\"\n        end_indicator = self._indicator + batch_size\n        if end_indicator > self._num_samples:\n            if self._need_shuffle:\n                self._shuffle_data()\n                self._indicator = 0\n                end_indicator = self._indicator + batch_size\n            else:\n                raise Exception('have no more samples')\n        if end_indicator > self._num_samples:\n            # 去除不足batch_size剩余的样本\n            raise Exception('batch size is larger than the remaining samples')\n        batch_data = self._data[self._indicator:end_indicator]\n        batch_labels = self._lables[self._indicator:end_indicator]\n        self._indicator = end_indicator\n        return batch_data, batch_labels\n\n\ntrain_data = CifarData(train_filenames, True)\ntest_data = CifarData(test_filenames, False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:22.276976Z","iopub.execute_input":"2022-07-29T01:47:22.277721Z","iopub.status.idle":"2022-07-29T01:47:26.593719Z","shell.execute_reply.started":"2022-07-29T01:47:22.277680Z","shell.execute_reply":"2022-07-29T01:47:26.592729Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(50000, 3072)\n(50000,)\n[6 9 9 4 1]\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n","output_type":"stream"}]},{"cell_type":"code","source":"t = tf.constant(np.ones((100, 32, 32, 32)))\nprint(tf.pad(t, [[0, 0], [0, 0], [0, 0], [16, 16]]))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:26.595170Z","iopub.execute_input":"2022-07-29T01:47:26.595521Z","iopub.status.idle":"2022-07-29T01:47:26.732312Z","shell.execute_reply.started":"2022-07-29T01:47:26.595485Z","shell.execute_reply":"2022-07-29T01:47:26.731355Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Tensor(\"Pad:0\", shape=(100, 32, 32, 64), dtype=float64)\n","output_type":"stream"}]},{"cell_type":"code","source":"x = tf.constant(np.ones((10, 32, 32, 32)))\ntest = tf.layers.conv2d(x,\n                        64,\n                        (7, 7),\n                        strides=(2, 2),\n                        padding='same',\n                        activation=tf.nn.relu,\n                        name='conv_test')\nprint(test) # Tensor(\"conv_test/Relu:0\", shape=(10, 16, 16, 64), dtype=float64)\nprint(type(test)) #< class 'tensorflow.python.framework.ops.Tensor'>\nprint(test.get_shape()) # (10, 16, 16, 64)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:26.733644Z","iopub.execute_input":"2022-07-29T01:47:26.734170Z","iopub.status.idle":"2022-07-29T01:47:26.765314Z","shell.execute_reply.started":"2022-07-29T01:47:26.734134Z","shell.execute_reply":"2022-07-29T01:47:26.764327Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Tensor(\"conv_test/Relu:0\", shape=(10, 16, 16, 64), dtype=float64)\n<class 'tensorflow.python.framework.ops.Tensor'>\n(10, 16, 16, 64)\n","output_type":"stream"}]},{"cell_type":"code","source":"def residual_block(x, output_channel):\n    \"\"\"某个残差块的实现\"\"\"\n    input_channel = x.get_shape().as_list()[-1]\n    # 如果输出通道是输入通道的两倍，需要增加维度increase_dim=True\n    if input_channel * 2 == output_channel:\n        increase_dim = True\n        strides = (2, 2)\n    # 如果输入通道和输出通道一致，图像大小保持不变\n    elif input_channel == output_channel:\n        increase_dim = False\n        strides = (1, 1)\n    else:\n        raise Exception(\"input channel can't match output channel\")\n    conv1 = tf.layers.conv2d(x,\n                             output_channel,\n                             (3, 3),\n                             strides=strides,\n                             padding='same',\n                             activation=tf.nn.relu,\n                             name='conv1')\n    conv2 = tf.layers.conv2d(conv1,\n                             output_channel,\n                             (3, 3),\n                             strides=(1, 1),\n                             padding='same',\n                             activation=tf.nn.relu,\n                             name='conv2')\n    if increase_dim:\n        # 平均值和最大值池化都可以选\n        pooled_x = tf.layers.average_pooling2d(x,\n                                               (2, 2),\n                                               (2, 2),\n                                               padding='valid')\n        padded_x = tf.pad(pooled_x,\n                          [[0, 0], [0, 0], [0, 0],\n                           [input_channel // 2, input_channel // 2]])\n    else:\n        padded_x = x\n    # 确保形状尺寸相同才能残差连接\n    output_x = conv2 + padded_x\n    return output_x\n\n\ndef ResNet(x, num_residual_blocks,  # 每一层的残差块数目\n           num_filter_base,  # 通道数\n           class_num):\n    \"\"\"residual network implementation\"\"\"\n    # 降采样次数 残差块数目\n    num_subsampling = len(num_residual_blocks)\n    layers = []\n    input_size = x.get_shape().as_list()[1:]\n    with tf.variable_scope('conv0'):\n        # 首先经过一个普通卷积\n        conv0 = tf.layers.conv2d(x,\n                                 num_filter_base,\n                                 (3, 3),\n                                 strides=(1, 1),\n                                 padding='same',\n                                 activation=tf.nn.relu,\n                                 name='conv0')\n        layers.append(conv0)\n    for sample_id in range(num_subsampling):\n        for i in range(num_residual_blocks[sample_id]):\n            with tf.variable_scope(f'conv{sample_id}_{i}'):\n                conv = residual_block(layers[-1],\n                                      num_filter_base * (2 ** sample_id))  # 通道数不断翻倍\n                layers.append(conv)\n    # 判断最终的形状是否正确\n    multipliter = 2 ** (num_subsampling - 1)\n    assert layers[-1].get_shape().as_list()[1:]\\\n            == [input_size[0] / multipliter,\n                input_size[1] / multipliter,\n                num_filter_base * multipliter]\n    with tf.variable_scope('fc'):\n        global_pool = tf.reduce_mean(layers[-1], [1, 2])  # 对width(1轴)和height(2轴)求平均\n        logits = tf.layers.dense(global_pool, class_num)\n        layers.append(logits)\n    return layers[-1]","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:26.766718Z","iopub.execute_input":"2022-07-29T01:47:26.767217Z","iopub.status.idle":"2022-07-29T01:47:26.784338Z","shell.execute_reply.started":"2022-07-29T01:47:26.767179Z","shell.execute_reply":"2022-07-29T01:47:26.783320Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"x = tf.placeholder(tf.float32, [None, 3072])\ny = tf.placeholder(tf.int64, [None])\nx_image = tf.reshape(x, [-1, 3, 32, 32])\nx_image = tf.transpose(x_image, perm=[0, 2, 3, 1])\ny_ = ResNet(x_image, [2, 3, 2], 32, 10)\nprint(y_.get_shape())\nloss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\npredict = tf.argmax(y_, 1)\ncorrect_prediction = tf.equal(predict, y)  # y是真实值\n# 计算张量维度上元素的平均值\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\nwith tf.name_scope('train_op'):\n    # 这里计算梯度并更新了梯度\n    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:26.785920Z","iopub.execute_input":"2022-07-29T01:47:26.786646Z","iopub.status.idle":"2022-07-29T01:47:27.731044Z","shell.execute_reply.started":"2022-07-29T01:47:26.786609Z","shell.execute_reply":"2022-07-29T01:47:27.730125Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(?, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"init = tf.global_variables_initializer()  # 低版本tf必须要做\nbatch_size = 20\ntrain_steps = 10000\ntest_steps = 100\nwith tf.Session() as s:\n    s.run(init)  # 低版本tf必须要做\n    start = time.time()\n    for i in range(train_steps):\n        batch_data, batch_labels = train_data.next_batch(batch_size)\n        loss_val, accu_val, _ = s.run([loss, accuracy, train_op],\n                                      feed_dict={x: batch_data, y: batch_labels})\n        if (i + 1) % 100 == 0:\n            print('[Train] Step: %d, loss: %4.5f, accuracy: %4.5f'\n                  % (i + 1, loss_val, accu_val))\n            end = time.time()\n            print(f'just 100 steps take time: {end - start}s')\n            start=end\n        if (i + 1) % 1000 == 0:\n            test_data = CifarData(test_filenames, False)  # 重新拿测试集\n            all_test_accu_val = []\n            for j in range(test_steps):\n                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n                test_accu_val = s.run([accuracy],\n                                      feed_dict={x: test_batch_data, y: test_batch_labels})\n                all_test_accu_val.append(test_accu_val)\n            test_accu = np.mean(all_test_accu_val)\n            print('[Test ] Step: %d, accuracy: %4.5f' % (i + 1, test_accu))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-29T01:47:27.732455Z","iopub.execute_input":"2022-07-29T01:47:27.732804Z","iopub.status.idle":"2022-07-29T03:14:30.287723Z","shell.execute_reply.started":"2022-07-29T01:47:27.732769Z","shell.execute_reply":"2022-07-29T03:14:30.286683Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-07-29 01:47:27.745103: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2022-07-29 01:47:27.749267: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz\n2022-07-29 01:47:27.749629: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55bd179654f0 executing computations on platform Host. Devices:\n2022-07-29 01:47:27.749661: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","output_type":"stream"},{"name":"stdout","text":"[Train] Step: 100, loss: 1.89894, accuracy: 0.15000\njust 100 steps take time:51.49335980415344s\n[Train] Step: 200, loss: 1.83713, accuracy: 0.45000\njust 100 steps take time:51.30489730834961s\n[Train] Step: 300, loss: 1.99875, accuracy: 0.25000\njust 100 steps take time:50.69451022148132s\n[Train] Step: 400, loss: 1.62546, accuracy: 0.40000\njust 100 steps take time:50.85912036895752s\n[Train] Step: 500, loss: 1.38188, accuracy: 0.60000\njust 100 steps take time:50.74187183380127s\n[Train] Step: 600, loss: 1.41893, accuracy: 0.30000\njust 100 steps take time:51.5678608417511s\n[Train] Step: 700, loss: 1.65330, accuracy: 0.40000\njust 100 steps take time:50.965763568878174s\n[Train] Step: 800, loss: 1.95867, accuracy: 0.20000\njust 100 steps take time:50.82271432876587s\n[Train] Step: 900, loss: 1.40928, accuracy: 0.50000\njust 100 steps take time:51.45769000053406s\n[Train] Step: 1000, loss: 1.27976, accuracy: 0.55000\njust 100 steps take time:50.44248175621033s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659059772.5791888\n[Test ] Step: 1000, accuracy: 0.43400\n[Train] Step: 1100, loss: 1.16190, accuracy: 0.60000\njust 100 steps take time:65.35714316368103s\n[Train] Step: 1200, loss: 1.30393, accuracy: 0.55000\njust 100 steps take time:51.41529393196106s\n[Train] Step: 1300, loss: 1.77774, accuracy: 0.30000\njust 100 steps take time:50.52390122413635s\n[Train] Step: 1400, loss: 1.21191, accuracy: 0.50000\njust 100 steps take time:51.42277145385742s\n[Train] Step: 1500, loss: 1.39057, accuracy: 0.65000\njust 100 steps take time:50.47693610191345s\n[Train] Step: 1600, loss: 1.58696, accuracy: 0.45000\njust 100 steps take time:51.038663148880005s\n[Train] Step: 1700, loss: 1.52458, accuracy: 0.30000\njust 100 steps take time:51.20136117935181s\n[Train] Step: 1800, loss: 0.99176, accuracy: 0.60000\njust 100 steps take time:50.24559569358826s\n[Train] Step: 1900, loss: 1.31491, accuracy: 0.60000\njust 100 steps take time:51.273903131484985s\n[Train] Step: 2000, loss: 1.69036, accuracy: 0.55000\njust 100 steps take time:50.77232527732849s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659060296.4059744\n[Test ] Step: 2000, accuracy: 0.55500\n[Train] Step: 2100, loss: 1.21280, accuracy: 0.60000\njust 100 steps take time:65.0499758720398s\n[Train] Step: 2200, loss: 1.68290, accuracy: 0.35000\njust 100 steps take time:50.9217689037323s\n[Train] Step: 2300, loss: 1.47631, accuracy: 0.45000\njust 100 steps take time:50.417054891586304s\n[Train] Step: 2400, loss: 1.12329, accuracy: 0.65000\njust 100 steps take time:51.194427490234375s\n[Train] Step: 2500, loss: 1.43148, accuracy: 0.30000\njust 100 steps take time:50.504974126815796s\n[Train] Step: 2600, loss: 2.04459, accuracy: 0.20000\njust 100 steps take time:51.44419717788696s\n[Train] Step: 2700, loss: 0.77456, accuracy: 0.70000\njust 100 steps take time:50.165138483047485s\n[Train] Step: 2800, loss: 0.93801, accuracy: 0.55000\njust 100 steps take time:51.22868013381958s\n[Train] Step: 2900, loss: 1.78891, accuracy: 0.40000\njust 100 steps take time:51.10538101196289s\n[Train] Step: 3000, loss: 1.62611, accuracy: 0.50000\njust 100 steps take time:50.63956141471863s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659060819.195605\n[Test ] Step: 3000, accuracy: 0.59600\n[Train] Step: 3100, loss: 0.60553, accuracy: 0.85000\njust 100 steps take time:64.6964762210846s\n[Train] Step: 3200, loss: 1.05002, accuracy: 0.65000\njust 100 steps take time:51.13749122619629s\n[Train] Step: 3300, loss: 0.70948, accuracy: 0.80000\njust 100 steps take time:50.63987064361572s\n[Train] Step: 3400, loss: 1.07510, accuracy: 0.50000\njust 100 steps take time:51.455949783325195s\n[Train] Step: 3500, loss: 1.02815, accuracy: 0.60000\njust 100 steps take time:50.82698130607605s\n[Train] Step: 3600, loss: 1.27867, accuracy: 0.65000\njust 100 steps take time:51.33512353897095s\n[Train] Step: 3700, loss: 0.70002, accuracy: 0.75000\njust 100 steps take time:51.19123291969299s\n[Train] Step: 3800, loss: 1.18193, accuracy: 0.65000\njust 100 steps take time:51.23879647254944s\n[Train] Step: 3900, loss: 0.88903, accuracy: 0.75000\njust 100 steps take time:51.297725677490234s\n[Train] Step: 4000, loss: 1.27286, accuracy: 0.55000\njust 100 steps take time:51.091209173202515s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659061343.996472\n[Test ] Step: 4000, accuracy: 0.62500\n[Train] Step: 4100, loss: 0.83944, accuracy: 0.65000\njust 100 steps take time:65.17803740501404s\n[Train] Step: 4200, loss: 0.80018, accuracy: 0.65000\njust 100 steps take time:51.39962458610535s\n[Train] Step: 4300, loss: 0.61514, accuracy: 0.80000\njust 100 steps take time:50.52962017059326s\n[Train] Step: 4400, loss: 0.70985, accuracy: 0.70000\njust 100 steps take time:51.338762044906616s\n[Train] Step: 4500, loss: 0.81778, accuracy: 0.75000\njust 100 steps take time:50.79524898529053s\n[Train] Step: 4600, loss: 1.15223, accuracy: 0.60000\njust 100 steps take time:50.489261865615845s\n[Train] Step: 4700, loss: 0.75063, accuracy: 0.75000\njust 100 steps take time:50.680867195129395s\n[Train] Step: 4800, loss: 0.67266, accuracy: 0.65000\njust 100 steps take time:51.36958146095276s\n[Train] Step: 4900, loss: 0.94070, accuracy: 0.70000\njust 100 steps take time:50.44845986366272s\n[Train] Step: 5000, loss: 0.93163, accuracy: 0.65000\njust 100 steps take time:51.40986108779907s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659061867.0037022\n[Test ] Step: 5000, accuracy: 0.69900\n[Train] Step: 5100, loss: 0.66084, accuracy: 0.85000\njust 100 steps take time:65.28307962417603s\n[Train] Step: 5200, loss: 0.55801, accuracy: 0.80000\njust 100 steps take time:50.848788261413574s\n[Train] Step: 5300, loss: 0.51036, accuracy: 0.90000\njust 100 steps take time:50.555504322052s\n[Train] Step: 5400, loss: 0.86977, accuracy: 0.55000\njust 100 steps take time:51.330031633377075s\n[Train] Step: 5500, loss: 0.97829, accuracy: 0.75000\njust 100 steps take time:50.35428333282471s\n[Train] Step: 5600, loss: 1.21621, accuracy: 0.55000\njust 100 steps take time:51.31155276298523s\n[Train] Step: 5700, loss: 0.21757, accuracy: 0.95000\njust 100 steps take time:50.6983699798584s\n[Train] Step: 5800, loss: 0.84186, accuracy: 0.60000\njust 100 steps take time:50.79882049560547s\n[Train] Step: 5900, loss: 1.00385, accuracy: 0.60000\njust 100 steps take time:51.526543855667114s\n[Train] Step: 6000, loss: 0.79695, accuracy: 0.55000\njust 100 steps take time:50.47178673744202s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659062390.9484317\n[Test ] Step: 6000, accuracy: 0.70200\n[Train] Step: 6100, loss: 0.93968, accuracy: 0.60000\njust 100 steps take time:64.97532367706299s\n[Train] Step: 6200, loss: 0.49751, accuracy: 0.85000\njust 100 steps take time:51.2060227394104s\n[Train] Step: 6300, loss: 0.59253, accuracy: 0.80000\njust 100 steps take time:50.501365184783936s\n[Train] Step: 6400, loss: 0.76133, accuracy: 0.65000\njust 100 steps take time:50.88225603103638s\n[Train] Step: 6500, loss: 0.69485, accuracy: 0.80000\njust 100 steps take time:50.4257595539093s\n[Train] Step: 6600, loss: 0.85071, accuracy: 0.75000\njust 100 steps take time:51.355210304260254s\n[Train] Step: 6700, loss: 0.66039, accuracy: 0.70000\njust 100 steps take time:50.80911564826965s\n[Train] Step: 6800, loss: 0.58292, accuracy: 0.80000\njust 100 steps take time:51.20294904708862s\n[Train] Step: 6900, loss: 1.01253, accuracy: 0.70000\njust 100 steps take time:50.440696239471436s\n[Train] Step: 7000, loss: 1.10888, accuracy: 0.65000\njust 100 steps take time:51.62122130393982s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659062913.5665927\n[Test ] Step: 7000, accuracy: 0.71800\n[Train] Step: 7100, loss: 0.55880, accuracy: 0.90000\njust 100 steps take time:65.24098086357117s\n[Train] Step: 7200, loss: 1.12425, accuracy: 0.75000\njust 100 steps take time:50.60471200942993s\n[Train] Step: 7300, loss: 0.55346, accuracy: 0.90000\njust 100 steps take time:50.965327978134155s\n[Train] Step: 7400, loss: 0.22350, accuracy: 0.95000\njust 100 steps take time:50.97489643096924s\n[Train] Step: 7500, loss: 0.73228, accuracy: 0.70000\njust 100 steps take time:50.24743127822876s\n[Train] Step: 7600, loss: 0.46052, accuracy: 0.85000\njust 100 steps take time:51.50399899482727s\n[Train] Step: 7700, loss: 0.66680, accuracy: 0.75000\njust 100 steps take time:50.636990785598755s\n[Train] Step: 7800, loss: 0.38669, accuracy: 0.80000\njust 100 steps take time:50.9740469455719s\n[Train] Step: 7900, loss: 0.32207, accuracy: 0.90000\njust 100 steps take time:50.740057706832886s\n[Train] Step: 8000, loss: 0.40412, accuracy: 0.85000\njust 100 steps take time:51.02869534492493s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659063436.5339277\n[Test ] Step: 8000, accuracy: 0.72950\n[Train] Step: 8100, loss: 0.54754, accuracy: 0.75000\njust 100 steps take time:65.08697843551636s\n[Train] Step: 8200, loss: 0.69751, accuracy: 0.65000\njust 100 steps take time:50.550453662872314s\n[Train] Step: 8300, loss: 0.66947, accuracy: 0.70000\njust 100 steps take time:50.949408769607544s\n[Train] Step: 8400, loss: 0.51469, accuracy: 0.80000\njust 100 steps take time:49.88017678260803s\n[Train] Step: 8500, loss: 0.54694, accuracy: 0.85000\njust 100 steps take time:51.11290407180786s\n[Train] Step: 8600, loss: 0.29216, accuracy: 0.95000\njust 100 steps take time:49.743565797805786s\n[Train] Step: 8700, loss: 0.77402, accuracy: 0.75000\njust 100 steps take time:50.81230688095093s\n[Train] Step: 8800, loss: 0.53512, accuracy: 0.85000\njust 100 steps take time:50.104740858078s\n[Train] Step: 8900, loss: 0.53799, accuracy: 0.80000\njust 100 steps take time:50.39414095878601s\n[Train] Step: 9000, loss: 0.53762, accuracy: 0.75000\njust 100 steps take time:51.294787645339966s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659063956.287908\n[Test ] Step: 9000, accuracy: 0.74000\n[Train] Step: 9100, loss: 0.75658, accuracy: 0.75000\njust 100 steps take time:64.22053956985474s\n[Train] Step: 9200, loss: 0.88787, accuracy: 0.75000\njust 100 steps take time:50.405940771102905s\n[Train] Step: 9300, loss: 0.62464, accuracy: 0.80000\njust 100 steps take time:51.06071996688843s\n[Train] Step: 9400, loss: 0.55133, accuracy: 0.85000\njust 100 steps take time:49.858800649642944s\n[Train] Step: 9500, loss: 0.60261, accuracy: 0.80000\njust 100 steps take time:51.25375556945801s\n[Train] Step: 9600, loss: 0.55514, accuracy: 0.80000\njust 100 steps take time:49.79895305633545s\n[Train] Step: 9700, loss: 0.43733, accuracy: 0.90000\njust 100 steps take time:49.811110496520996s\n[Train] Step: 9800, loss: 1.11929, accuracy: 0.75000\njust 100 steps take time:49.44440293312073s\n[Train] Step: 9900, loss: 0.53423, accuracy: 0.85000\njust 100 steps take time:49.14072823524475s\n[Train] Step: 10000, loss: 0.74495, accuracy: 0.85000\njust 100 steps take time:48.661343812942505s\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659064470.2750757\n[Test ] Step: 10000, accuracy: 0.75150\n","output_type":"stream"}]}]}