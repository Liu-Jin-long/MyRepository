{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==1.13.1","metadata":{"execution":{"iopub.status.busy":"2022-07-28T14:21:58.538853Z","iopub.execute_input":"2022-07-28T14:21:58.539365Z","iopub.status.idle":"2022-07-28T14:23:00.743589Z","shell.execute_reply.started":"2022-07-28T14:21:58.539264Z","shell.execute_reply":"2022-07-28T14:23:00.742023Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==1.13.1\n  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.6/367.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.2)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\nCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.19.4)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.37.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.21.6)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.16.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.43.0)\nCollecting tensorboard<1.14.0,>=1.13.0\n  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.4.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.7.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.7)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (2.1.2)\nRequirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.12.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\nInstalling collected packages: tensorflow-estimator, astor, keras-applications, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.4\n    Uninstalling tensorflow-2.6.4:\n      Successfully uninstalled tensorflow-2.6.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 1.13.1 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.13.1 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorflow<3.0,>=1.15.0, but you have tensorflow 1.13.1 which is incompatible.\npytorch-lightning 1.6.5 requires tensorboard>=2.2.0, but you have tensorboard 1.13.1 which is incompatible.\nexplainable-ai-sdk 1.3.3 requires tensorflow>=1.15.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport time\nimport pickle\nimport numpy as np\n\nprint(tf.__version__)\nCIFAR_DIR = '/kaggle/input/cifar10/cifar-10-batches-py'\nprint(os.listdir(CIFAR_DIR))","metadata":{"execution":{"iopub.status.busy":"2022-07-28T14:23:00.748755Z","iopub.execute_input":"2022-07-28T14:23:00.749127Z","iopub.status.idle":"2022-07-28T14:23:01.930388Z","shell.execute_reply.started":"2022-07-28T14:23:00.749077Z","shell.execute_reply":"2022-07-28T14:23:01.928922Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"},{"name":"stdout","text":"1.13.1\n['data_batch_1', 'data_batch_2', 'batches.meta', 'test_batch', 'data_batch_3', 'data_batch_5', 'data_batch_4', 'readme.html']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_filenames = [os.path.join(CIFAR_DIR, f'data_batch_{i}') for i in range(1,6)]\ntest_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\nprint(train_filenames)\nprint(test_filenames)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-28T14:23:01.933328Z","iopub.execute_input":"2022-07-28T14:23:01.934678Z","iopub.status.idle":"2022-07-28T14:23:01.944482Z","shell.execute_reply.started":"2022-07-28T14:23:01.934598Z","shell.execute_reply":"2022-07-28T14:23:01.941947Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['/kaggle/input/cifar10/cifar-10-batches-py/data_batch_1', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_2', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_3', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_4', '/kaggle/input/cifar10/cifar-10-batches-py/data_batch_5']\n['/kaggle/input/cifar10/cifar-10-batches-py/test_batch']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.random.permutation(10))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-28T14:23:01.947492Z","iopub.execute_input":"2022-07-28T14:23:01.947972Z","iopub.status.idle":"2022-07-28T14:23:01.966331Z","shell.execute_reply.started":"2022-07-28T14:23:01.947927Z","shell.execute_reply":"2022-07-28T14:23:01.964664Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[1 2 4 7 9 0 8 6 5 3]\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(filename):\n    \"\"\"前面是图片特征，后面是图片分类标签\"\"\"\n    with open(filename, 'rb') as f:\n        data = pickle.load(f, encoding='bytes')\n        return data[b'data'], data[b'labels']\n\n\n# tensorflow.Dataset\nclass CifarData:\n    def __init__(self, filenames, need_shuffle):\n        all_data = []\n        all_lables = []\n        for filename in filenames:\n            data, labels = load_data(filename)\n            all_data.append(data)  # all_data[0]列表中10000个存有(32*32*3=)3072个数的一维列表c\n            all_lables.append(labels)  # all_data[0]列表中10000个标签值\n        self._data = np.vstack(all_data)  # 垂直方向沿轴2堆叠 变为ndarray\n        self._data = self._data / 127.5 - 1  # 归一化到范围[-1,1]\n        self._lables = np.hstack(all_lables)  # 一维列表变成ndarray\n        print(self._data.shape)  # (50000, 3072) 每一张图像展平后的结果\n        print(self._lables.shape)\n        print(self._lables[:5])\n\n        self._num_samples = self._data.shape[0]  # 样本数\n        self._need_shuffle = need_shuffle  # 进行洗牌随机\n        self._indicator = 0\n        if self._need_shuffle:\n            self._shuffle_data()\n\n    def _shuffle_data(self):\n        # 通过随机排列下标进行随机样本\n        p = np.random.permutation(self._num_samples)  # 变成随机下标\n        self._data = self._data[p]\n        self._lables = self._lables[p]\n\n    def next_batch(self, batch_size):\n        \"\"\"return batch_size samples as a batch.\"\"\"\n        end_indicator = self._indicator + batch_size\n        if end_indicator > self._num_samples:\n            if self._need_shuffle:\n                self._shuffle_data()\n                self._indicator = 0\n                end_indicator = self._indicator + batch_size\n            else:\n                raise Exception('have no more samples')\n        if end_indicator > self._num_samples:\n            # 去除不足batch_size剩余的样本\n            raise Exception('batch size is larger than the remaining samples')\n        batch_data = self._data[self._indicator:end_indicator]\n        batch_labels = self._lables[self._indicator:end_indicator]\n        self._indicator = end_indicator\n        return batch_data, batch_labels\n\n\ntrain_data = CifarData(train_filenames, True)\ntest_data = CifarData(test_filenames, False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-28T14:23:01.969025Z","iopub.execute_input":"2022-07-28T14:23:01.969540Z","iopub.status.idle":"2022-07-28T14:23:07.406965Z","shell.execute_reply.started":"2022-07-28T14:23:01.969493Z","shell.execute_reply":"2022-07-28T14:23:07.404889Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(50000, 3072)\n(50000,)\n[6 9 9 4 1]\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\n","output_type":"stream"}]},{"cell_type":"code","source":"x = tf.placeholder(tf.float32, [None, 3072])\ny = tf.placeholder(tf.int64, [None])\nx_image = tf.reshape(x, [-1, 3, 32, 32])  # 原数据channels_first存储的\nx_image = tf.transpose(x_image, perm=[0, 2, 3, 1])  # 功类似np.rollaxis轴滚动","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-28T14:23:07.408680Z","iopub.execute_input":"2022-07-28T14:23:07.409411Z","iopub.status.idle":"2022-07-28T14:23:07.434552Z","shell.execute_reply.started":"2022-07-28T14:23:07.409363Z","shell.execute_reply":"2022-07-28T14:23:07.433220Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nconv1_1 = tf.layers.conv2d(x_image,\n                           32,  # output channel number\n                           (3, 3),  # kernel size\n                           # 明确指定stride时padding='same'也不能保持形状不变 就像output_size等于input_size/stride\n                           padding='same',\n                           activation=tf.nn.relu,\n                           name='conv1_1')\nconv1_2 = tf.layers.conv2d(conv1_1,\n                           32,\n                           (3, 3),\n                           padding='same',\n                           activation=tf.nn.relu,\n                           name='conv1_2')\n\npooling1 = tf.layers.max_pooling2d(conv1_2,\n                                   (2, 2),  # kernel size\n                                   (2, 2),  # stride\n                                   name='pool1')\n# pooling1输出形状 16 * 16 * 32\nconv2_1 = tf.layers.conv2d(pooling1,\n                           32,\n                           (3, 3),\n                           padding='same',\n                           activation=tf.nn.relu,\n                           name='conv2_1')\nconv2_2 = tf.layers.conv2d(conv2_1,\n                           32,\n                           (3, 3),\n                           padding='same',\n                           activation=tf.nn.relu,\n                           name='conv2_2')\npooling2 = tf.layers.max_pooling2d(conv2_2,\n                                   (2, 2),\n                                   (2, 2),\n                                   name='pool2')\n# pooling2输出形状 8 * 8 * 32\nconv3_1 = tf.layers.conv2d(pooling2,\n                           32,\n                           (3, 3),\n                           padding='same',\n                           activation=tf.nn.relu,\n                           name='conv3_1')\nconv3_2 = tf.layers.conv2d(conv3_1,\n                           32,\n                           (3, 3),\n                           padding='same',\n                           activation=tf.nn.relu,\n                           name='conv3_2')\n# # pooling3输出形状 4 * 4 * 32\npooling3 = tf.layers.max_pooling2d(conv3_2,\n                                   (2, 2),  # kernel size\n                                   (2, 2),  # stride\n                                   name='pool3')\nflatten = tf.layers.flatten(pooling3)\ny_ = tf.layers.dense(flatten, 10)\n# 深度学习中，logits就是最终的全连接层的输出\nloss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n# softmax(y_)->p->one_hot->loss=plog(p)\npredict = tf.argmax(y_, 1)\ncorrect_prediction = tf.equal(predict, y)  # y是真实值\n# 计算张量维度上元素的平均值\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\nwith tf.name_scope('train_op'):\n    # 这里计算梯度并更新了梯度\n    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-28T14:23:07.440143Z","iopub.execute_input":"2022-07-28T14:23:07.440488Z","iopub.status.idle":"2022-07-28T14:23:08.519934Z","shell.execute_reply.started":"2022-07-28T14:23:07.440457Z","shell.execute_reply":"2022-07-28T14:23:08.518243Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"init = tf.global_variables_initializer()  # 低版本tf必须要做\nbatch_size = 20\ntrain_steps = 10000\ntest_steps = 100\nwith tf.Session() as s:\n    s.run(init)  # 低版本tf必须要做\n    for i in range(train_steps):\n        batch_data, batch_labels = train_data.next_batch(batch_size)\n        loss_val, accu_val, _ = s.run([loss, accuracy, train_op],\n                                      feed_dict={x: batch_data, y: batch_labels})\n        if (i+1)%100==0:\n            print('[Train] Step: %d, loss: %4.5f, accuracy: %4.5f'\n                  % (i+1,loss_val,accu_val))\n        if (i+1)%1000==0:\n            test_data=CifarData(test_filenames,False) # 重新拿测试集\n            all_test_accu_val=[]\n            for j in range(test_steps):\n                test_batch_data,test_batch_labels=test_data.next_batch(batch_size)\n                test_accu_val=s.run([accuracy],\n                                    feed_dict={x:test_batch_data,y:test_batch_labels})\n                all_test_accu_val.append(test_accu_val)\n            test_accu=np.mean(all_test_accu_val)\n            print(f'now time={time.time()}')\n            print('[Test ] Step: %d, accuracy: %4.5f' % (i+1,test_accu))\n ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-28T14:26:59.108297Z","iopub.execute_input":"2022-07-28T14:26:59.108897Z","iopub.status.idle":"2022-07-28T14:47:14.920337Z","shell.execute_reply.started":"2022-07-28T14:26:59.108846Z","shell.execute_reply":"2022-07-28T14:47:14.918809Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[Train] Step: 100, loss: 2.43925, accuracy: 0.15000\n[Train] Step: 200, loss: 2.16907, accuracy: 0.20000\n[Train] Step: 300, loss: 1.65611, accuracy: 0.35000\n[Train] Step: 400, loss: 1.80444, accuracy: 0.35000\n[Train] Step: 500, loss: 2.00781, accuracy: 0.20000\n[Train] Step: 600, loss: 1.35989, accuracy: 0.60000\n[Train] Step: 700, loss: 1.28732, accuracy: 0.55000\n[Train] Step: 800, loss: 1.34693, accuracy: 0.55000\n[Train] Step: 900, loss: 1.24280, accuracy: 0.45000\n[Train] Step: 1000, loss: 1.16296, accuracy: 0.60000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659018544.6309347\n[Test ] Step: 1000, accuracy: 0.48850\n[Train] Step: 1100, loss: 0.97391, accuracy: 0.75000\n[Train] Step: 1200, loss: 0.95511, accuracy: 0.70000\n[Train] Step: 1300, loss: 1.02998, accuracy: 0.65000\n[Train] Step: 1400, loss: 1.43874, accuracy: 0.45000\n[Train] Step: 1500, loss: 1.37702, accuracy: 0.40000\n[Train] Step: 1600, loss: 0.96739, accuracy: 0.65000\n[Train] Step: 1700, loss: 1.03788, accuracy: 0.80000\n[Train] Step: 1800, loss: 1.51682, accuracy: 0.60000\n[Train] Step: 1900, loss: 1.03116, accuracy: 0.70000\n[Train] Step: 2000, loss: 0.86314, accuracy: 0.65000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659018671.55447\n[Test ] Step: 2000, accuracy: 0.57700\n[Train] Step: 2100, loss: 1.19397, accuracy: 0.70000\n[Train] Step: 2200, loss: 1.18606, accuracy: 0.55000\n[Train] Step: 2300, loss: 0.78287, accuracy: 0.70000\n[Train] Step: 2400, loss: 1.30816, accuracy: 0.40000\n[Train] Step: 2500, loss: 0.73152, accuracy: 0.75000\n[Train] Step: 2600, loss: 0.64811, accuracy: 0.80000\n[Train] Step: 2700, loss: 0.80808, accuracy: 0.70000\n[Train] Step: 2800, loss: 0.82631, accuracy: 0.70000\n[Train] Step: 2900, loss: 1.15191, accuracy: 0.55000\n[Train] Step: 3000, loss: 1.05054, accuracy: 0.65000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659018793.20344\n[Test ] Step: 3000, accuracy: 0.63650\n[Train] Step: 3100, loss: 0.86003, accuracy: 0.75000\n[Train] Step: 3200, loss: 0.61194, accuracy: 0.70000\n[Train] Step: 3300, loss: 1.11464, accuracy: 0.50000\n[Train] Step: 3400, loss: 1.05653, accuracy: 0.70000\n[Train] Step: 3500, loss: 0.88422, accuracy: 0.65000\n[Train] Step: 3600, loss: 0.97575, accuracy: 0.70000\n[Train] Step: 3700, loss: 1.01455, accuracy: 0.75000\n[Train] Step: 3800, loss: 0.93391, accuracy: 0.65000\n[Train] Step: 3900, loss: 1.02774, accuracy: 0.75000\n[Train] Step: 4000, loss: 0.83267, accuracy: 0.70000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659018916.2238824\n[Test ] Step: 4000, accuracy: 0.67500\n[Train] Step: 4100, loss: 0.64694, accuracy: 0.75000\n[Train] Step: 4200, loss: 0.91183, accuracy: 0.60000\n[Train] Step: 4300, loss: 0.57283, accuracy: 0.75000\n[Train] Step: 4400, loss: 0.73988, accuracy: 0.70000\n[Train] Step: 4500, loss: 0.58673, accuracy: 0.85000\n[Train] Step: 4600, loss: 1.66619, accuracy: 0.45000\n[Train] Step: 4700, loss: 1.16876, accuracy: 0.70000\n[Train] Step: 4800, loss: 1.05432, accuracy: 0.70000\n[Train] Step: 4900, loss: 1.31583, accuracy: 0.60000\n[Train] Step: 5000, loss: 0.47240, accuracy: 0.80000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659019036.2107482\n[Test ] Step: 5000, accuracy: 0.68300\n[Train] Step: 5100, loss: 1.46334, accuracy: 0.55000\n[Train] Step: 5200, loss: 0.75963, accuracy: 0.75000\n[Train] Step: 5300, loss: 0.70132, accuracy: 0.75000\n[Train] Step: 5400, loss: 1.08345, accuracy: 0.55000\n[Train] Step: 5500, loss: 1.07484, accuracy: 0.60000\n[Train] Step: 5600, loss: 0.93453, accuracy: 0.75000\n[Train] Step: 5700, loss: 1.54316, accuracy: 0.55000\n[Train] Step: 5800, loss: 0.71720, accuracy: 0.80000\n[Train] Step: 5900, loss: 1.00081, accuracy: 0.70000\n[Train] Step: 6000, loss: 1.00041, accuracy: 0.75000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659019154.1172955\n[Test ] Step: 6000, accuracy: 0.68400\n[Train] Step: 6100, loss: 0.77263, accuracy: 0.65000\n[Train] Step: 6200, loss: 0.57064, accuracy: 0.80000\n[Train] Step: 6300, loss: 0.58285, accuracy: 0.90000\n[Train] Step: 6400, loss: 1.40125, accuracy: 0.50000\n[Train] Step: 6500, loss: 0.98968, accuracy: 0.65000\n[Train] Step: 6600, loss: 1.00954, accuracy: 0.55000\n[Train] Step: 6700, loss: 0.49019, accuracy: 0.90000\n[Train] Step: 6800, loss: 0.62032, accuracy: 0.70000\n[Train] Step: 6900, loss: 0.71522, accuracy: 0.70000\n[Train] Step: 7000, loss: 0.75803, accuracy: 0.70000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659019275.392346\n[Test ] Step: 7000, accuracy: 0.71750\n[Train] Step: 7100, loss: 0.86880, accuracy: 0.60000\n[Train] Step: 7200, loss: 0.72228, accuracy: 0.80000\n[Train] Step: 7300, loss: 0.69203, accuracy: 0.75000\n[Train] Step: 7400, loss: 0.89739, accuracy: 0.70000\n[Train] Step: 7500, loss: 1.10746, accuracy: 0.75000\n[Train] Step: 7600, loss: 0.58556, accuracy: 0.85000\n[Train] Step: 7700, loss: 0.72993, accuracy: 0.70000\n[Train] Step: 7800, loss: 0.94244, accuracy: 0.65000\n[Train] Step: 7900, loss: 0.49254, accuracy: 0.80000\n[Train] Step: 8000, loss: 0.76930, accuracy: 0.75000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659019396.7303774\n[Test ] Step: 8000, accuracy: 0.72800\n[Train] Step: 8100, loss: 1.06285, accuracy: 0.55000\n[Train] Step: 8200, loss: 0.95874, accuracy: 0.70000\n[Train] Step: 8300, loss: 0.87587, accuracy: 0.55000\n[Train] Step: 8400, loss: 1.01700, accuracy: 0.65000\n[Train] Step: 8500, loss: 0.79368, accuracy: 0.70000\n[Train] Step: 8600, loss: 0.55154, accuracy: 0.85000\n[Train] Step: 8700, loss: 0.42511, accuracy: 0.90000\n[Train] Step: 8800, loss: 0.70886, accuracy: 0.70000\n[Train] Step: 8900, loss: 0.52265, accuracy: 0.75000\n[Train] Step: 9000, loss: 0.64186, accuracy: 0.75000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659019515.7934601\n[Test ] Step: 9000, accuracy: 0.72350\n[Train] Step: 9100, loss: 0.62304, accuracy: 0.75000\n[Train] Step: 9200, loss: 0.48072, accuracy: 0.90000\n[Train] Step: 9300, loss: 0.45048, accuracy: 0.80000\n[Train] Step: 9400, loss: 0.67878, accuracy: 0.70000\n[Train] Step: 9500, loss: 0.69304, accuracy: 0.75000\n[Train] Step: 9600, loss: 0.60176, accuracy: 0.75000\n[Train] Step: 9700, loss: 0.93394, accuracy: 0.75000\n[Train] Step: 9800, loss: 0.59534, accuracy: 0.75000\n[Train] Step: 9900, loss: 0.47439, accuracy: 0.85000\n[Train] Step: 10000, loss: 0.81266, accuracy: 0.65000\n(10000, 3072)\n(10000,)\n[3 8 8 0 6]\nnow time=1659019634.911167\n[Test ] Step: 10000, accuracy: 0.70800\n","output_type":"stream"}]}]}